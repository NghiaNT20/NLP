{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20. How to find the cosine similarity of two documents?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Find the cosine similarity between two given documents\n",
    "\n",
    "Input: \n",
    "\n",
    "text1='Taj Mahal is a tourist place in India'\n",
    "\n",
    "text2='Great Wall of China is a tourist place in china'\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "\n",
    "[[1.         0.45584231]\n",
    "\n",
    " [0.45584231 1.        ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp39-cp39-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/11.0 MB 1.4 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.1/11.0 MB 919.0 kB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/11.0 MB 919.0 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.2/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/11.0 MB 1.2 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 0.3/11.0 MB 1.3 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.4/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.5/11.0 MB 1.5 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 0.6/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.7/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.8/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 0.8/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.8/11.0 MB 1.5 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.9/11.0 MB 1.4 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.0/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 1.1/11.0 MB 1.3 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.1/11.0 MB 1.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.2/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.3/11.0 MB 1.2 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 1.4/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.4/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.5/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 1.1 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.6/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.7/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.7/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.7/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.0 MB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.8/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.0 MB 1.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.0 MB 991.5 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.0 MB 980.8 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.0 MB 980.8 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.9/11.0 MB 980.8 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.9/11.0 MB 952.9 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.0/11.0 MB 948.5 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.0/11.0 MB 934.9 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.0/11.0 MB 924.5 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.0/11.0 MB 915.7 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.0/11.0 MB 912.2 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.0 MB 904.2 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.0 MB 897.3 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.0 MB 897.3 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 2.1/11.0 MB 869.8 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.1/11.0 MB 863.0 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.2/11.0 MB 855.0 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.2/11.0 MB 852.7 kB/s eta 0:00:11\n",
      "   ------- -------------------------------- 2.2/11.0 MB 852.7 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.2/11.0 MB 833.9 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.2/11.0 MB 833.9 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.2/11.0 MB 813.8 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.2/11.0 MB 807.3 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.3/11.0 MB 796.6 kB/s eta 0:00:11\n",
      "   -------- ------------------------------- 2.3/11.0 MB 787.1 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 787.1 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 769.4 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 769.4 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 756.8 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 744.4 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 744.4 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 736.3 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 736.3 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 736.3 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.3/11.0 MB 736.3 kB/s eta 0:00:12\n",
      "   -------- ------------------------------- 2.4/11.0 MB 700.9 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 700.9 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 688.0 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 688.0 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 688.0 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 675.7 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 666.7 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 666.7 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 2.4/11.0 MB 652.7 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 2.4/11.0 MB 652.7 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 2.5/11.0 MB 647.3 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 2.5/11.0 MB 636.8 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 2.5/11.0 MB 636.8 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 634.4 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 634.4 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 622.4 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 622.4 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 618.0 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 618.0 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.5/11.0 MB 608.9 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.6/11.0 MB 606.9 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.6/11.0 MB 606.9 kB/s eta 0:00:14\n",
      "   --------- ------------------------------ 2.6/11.0 MB 596.2 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 596.2 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 586.0 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 586.0 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 582.3 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 582.3 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 568.8 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 568.8 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.6/11.0 MB 568.8 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.7/11.0 MB 560.0 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.7/11.0 MB 560.0 kB/s eta 0:00:15\n",
      "   --------- ------------------------------ 2.7/11.0 MB 553.3 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 553.3 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 544.8 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 544.8 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 544.8 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 544.8 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 530.4 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 530.4 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 521.2 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 521.2 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 521.2 kB/s eta 0:00:16\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   --------- ------------------------------ 2.7/11.0 MB 514.3 kB/s eta 0:00:17\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 477.3 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 477.3 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 473.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 473.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 473.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 473.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 473.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 473.9 kB/s eta 0:00:18\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 455.4 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 455.4 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 455.4 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 455.4 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 455.4 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 455.4 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 439.1 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 439.1 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 434.8 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 434.8 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 434.8 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 434.8 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 434.8 kB/s eta 0:00:19\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 423.7 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 423.7 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 419.3 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 419.3 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.8/11.0 MB 419.3 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 413.7 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 413.7 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 413.7 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 406.9 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 406.9 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 406.9 kB/s eta 0:00:20\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 402.7 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 402.7 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 402.7 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 402.7 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 396.9 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 394.1 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 394.1 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 394.1 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 394.1 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 394.1 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 386.2 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 386.2 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 2.9/11.0 MB 386.2 kB/s eta 0:00:21\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 382.1 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 382.1 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 382.1 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 377.9 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 377.9 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 377.9 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 373.8 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 373.8 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 373.8 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 370.7 kB/s eta 0:00:22\n",
      "   ---------- ----------------------------- 3.0/11.0 MB 370.7 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 368.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 368.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 368.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 366.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.0/11.0 MB 366.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 365.1 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 364.8 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 364.8 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 363.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 363.7 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 363.7 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 360.9 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 360.9 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 360.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.1/11.0 MB 360.0 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 359.8 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 358.4 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 358.4 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 358.2 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 356.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 356.3 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 356.7 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 356.4 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.2/11.0 MB 356.4 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 355.7 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 355.6 kB/s eta 0:00:22\n",
      "   ----------- ---------------------------- 3.3/11.0 MB 354.9 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.3/11.0 MB 355.3 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.3/11.0 MB 355.7 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.3/11.0 MB 355.7 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.3/11.0 MB 353.8 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 354.2 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 354.2 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 353.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 353.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 352.8 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 352.7 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 352.0 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 352.0 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.4/11.0 MB 351.8 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.2 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.1 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.1 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.5 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.2 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 351.2 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.5/11.0 MB 350.1 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.6/11.0 MB 349.9 kB/s eta 0:00:22\n",
      "   ------------ --------------------------- 3.6/11.0 MB 349.9 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.6/11.0 MB 349.3 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.6/11.0 MB 348.1 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.6/11.0 MB 348.5 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.6/11.0 MB 348.5 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.6/11.0 MB 348.0 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.6/11.0 MB 348.4 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.7/11.0 MB 348.2 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.7/11.0 MB 347.7 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.7/11.0 MB 347.7 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.7/11.0 MB 348.1 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.7/11.0 MB 347.0 kB/s eta 0:00:22\n",
      "   ------------- -------------------------- 3.7/11.0 MB 347.9 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.7/11.0 MB 347.8 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.7/11.0 MB 347.7 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.8/11.0 MB 348.6 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.8/11.0 MB 348.0 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.8/11.0 MB 348.9 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.8/11.0 MB 348.9 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.8/11.0 MB 348.8 kB/s eta 0:00:21\n",
      "   ------------- -------------------------- 3.8/11.0 MB 348.7 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 348.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 348.6 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 348.9 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 348.8 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 348.8 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 348.8 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 346.3 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 347.2 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 3.9/11.0 MB 346.2 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 346.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 346.1 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 346.0 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 346.0 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 344.5 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 344.9 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 344.4 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 344.4 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 344.4 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 342.9 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.0/11.0 MB 342.9 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 341.9 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 341.9 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 341.4 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 341.4 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 341.4 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 340.0 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 340.0 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 340.0 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 340.0 kB/s eta 0:00:21\n",
      "   -------------- ------------------------- 4.1/11.0 MB 340.0 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.1/11.0 MB 336.0 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.1/11.0 MB 336.0 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.1/11.0 MB 336.0 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.1/11.0 MB 335.2 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.1/11.0 MB 335.2 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 333.9 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 333.8 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 333.4 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 333.4 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 333.4 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 332.5 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 332.1 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 332.1 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.2/11.0 MB 331.7 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 331.7 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 331.7 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 331.3 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 331.3 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 330.9 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 330.9 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 330.8 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.3/11.0 MB 331.2 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.4/11.0 MB 331.2 kB/s eta 0:00:21\n",
      "   --------------- ------------------------ 4.4/11.0 MB 331.2 kB/s eta 0:00:20\n",
      "   --------------- ------------------------ 4.4/11.0 MB 331.2 kB/s eta 0:00:20\n",
      "   --------------- ------------------------ 4.4/11.0 MB 331.2 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.4/11.0 MB 331.2 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.4/11.0 MB 331.9 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.4/11.0 MB 331.9 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 332.3 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 333.0 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 333.4 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 333.4 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.5/11.0 MB 334.1 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.4 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.4 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.4 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.4 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 335.1 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.0 kB/s eta 0:00:20\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.3 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 4.6/11.0 MB 334.3 kB/s eta 0:00:19\n",
      "   ---------------- ----------------------- 4.7/11.0 MB 334.7 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 334.3 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 334.6 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 334.2 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.7/11.0 MB 335.0 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 335.3 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 335.3 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 335.6 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 335.2 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 336.3 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.8/11.0 MB 336.6 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 337.3 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 336.9 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 338.0 kB/s eta 0:00:19\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 338.6 kB/s eta 0:00:18\n",
      "   ----------------- ---------------------- 4.9/11.0 MB 339.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.0/11.0 MB 339.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.0/11.0 MB 340.6 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.0/11.0 MB 340.6 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.0/11.0 MB 341.6 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.1/11.0 MB 342.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.1/11.0 MB 343.3 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.1/11.0 MB 343.9 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.1/11.0 MB 343.9 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.1/11.0 MB 343.9 kB/s eta 0:00:18\n",
      "   ------------------ --------------------- 5.2/11.0 MB 345.1 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 5.2/11.0 MB 345.4 kB/s eta 0:00:17\n",
      "   ------------------ --------------------- 5.2/11.0 MB 345.4 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.2/11.0 MB 346.0 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.2/11.0 MB 346.7 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.3/11.0 MB 347.3 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.3/11.0 MB 347.2 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.3/11.0 MB 348.2 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.3/11.0 MB 348.8 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.4/11.0 MB 349.4 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.4/11.0 MB 349.4 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.4/11.0 MB 349.4 kB/s eta 0:00:17\n",
      "   ------------------- -------------------- 5.4/11.0 MB 349.9 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 5.4/11.0 MB 349.9 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 5.4/11.0 MB 350.1 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 5.4/11.0 MB 349.8 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 5.5/11.0 MB 350.4 kB/s eta 0:00:16\n",
      "   ------------------- -------------------- 5.5/11.0 MB 350.6 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.5/11.0 MB 350.6 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.5/11.0 MB 350.8 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.5/11.0 MB 350.8 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.6/11.0 MB 352.0 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.6/11.0 MB 351.6 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.6/11.0 MB 352.2 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.6/11.0 MB 352.1 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.3 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.3 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.3 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.1 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.1 kB/s eta 0:00:16\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.4 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.6 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.6 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 5.7/11.0 MB 353.6 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 5.7/11.0 MB 351.5 kB/s eta 0:00:15\n",
      "   -------------------- ------------------- 5.8/11.0 MB 351.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 351.4 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 351.4 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 351.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 351.6 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 351.6 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 350.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.8/11.0 MB 351.1 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 350.7 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 351.0 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 351.2 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 350.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 351.1 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 351.1 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 351.1 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 5.9/11.0 MB 349.7 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 350.0 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 349.9 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 349.9 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 349.9 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 348.3 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 348.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 348.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 348.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 347.8 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 347.1 kB/s eta 0:00:15\n",
      "   --------------------- ------------------ 6.0/11.0 MB 347.1 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 346.8 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 346.8 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 346.1 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 346.3 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 346.3 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 346.3 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 345.6 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 345.6 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.1/11.0 MB 345.9 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 345.5 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 345.5 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 345.5 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 344.0 kB/s eta 0:00:15\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 344.2 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 344.2 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 344.2 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 344.2 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 342.6 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 342.6 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 342.6 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 341.4 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.2/11.0 MB 341.4 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 340.8 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 340.8 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 340.2 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 340.2 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 339.6 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 339.6 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 339.6 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 338.4 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 338.1 kB/s eta 0:00:14\n",
      "   ---------------------- ----------------- 6.3/11.0 MB 338.1 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.3/11.0 MB 337.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.3/11.0 MB 337.8 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 337.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 337.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 336.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 336.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 335.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 335.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 335.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 334.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 334.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 334.1 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 334.1 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 333.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.4/11.0 MB 333.5 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 332.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 332.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 332.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 331.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 331.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 330.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 330.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 330.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 330.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 330.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 329.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 329.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 329.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 327.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 327.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 327.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.5/11.0 MB 327.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 326.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 326.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 326.2 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 324.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 324.6 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 324.4 kB/s eta 0:00:14\n",
      "   ----------------------- ---------------- 6.6/11.0 MB 324.4 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 323.9 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 323.9 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 323.2 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 323.2 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 323.2 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 322.7 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.6/11.0 MB 322.7 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 322.7 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 322.7 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 322.7 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 322.7 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 321.8 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 322.0 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 321.6 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 321.6 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.7/11.0 MB 321.6 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 321.6 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 321.6 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 321.1 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 321.1 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 320.9 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 320.5 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 320.5 kB/s eta 0:00:14\n",
      "   ------------------------ --------------- 6.8/11.0 MB 320.7 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.9/11.0 MB 321.0 kB/s eta 0:00:13\n",
      "   ------------------------ --------------- 6.9/11.0 MB 320.7 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 6.9/11.0 MB 321.2 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 6.9/11.0 MB 321.0 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 6.9/11.0 MB 321.3 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 6.9/11.0 MB 321.5 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 6.9/11.0 MB 321.3 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.0/11.0 MB 321.8 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.0/11.0 MB 321.5 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.0/11.0 MB 322.0 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.0/11.0 MB 322.5 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.0/11.0 MB 322.8 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.1/11.0 MB 322.8 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.1/11.0 MB 323.2 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.1/11.0 MB 323.7 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.1/11.0 MB 323.7 kB/s eta 0:00:13\n",
      "   ------------------------- -------------- 7.1/11.0 MB 324.2 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.2/11.0 MB 324.7 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.2/11.0 MB 325.1 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.2/11.0 MB 325.1 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.2/11.0 MB 325.4 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.2/11.0 MB 325.2 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.2/11.0 MB 325.4 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.8 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.8 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.8 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.6 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.6 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.6 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.9 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.3/11.0 MB 325.9 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.4/11.0 MB 325.4 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.4/11.0 MB 325.4 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.4/11.0 MB 325.2 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.4/11.0 MB 325.2 kB/s eta 0:00:12\n",
      "   -------------------------- ------------- 7.4/11.0 MB 325.4 kB/s eta 0:00:12\n",
      "   --------------------------- ------------ 7.4/11.0 MB 325.7 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.4/11.0 MB 325.4 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.5/11.0 MB 325.9 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.5/11.0 MB 325.7 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.5/11.0 MB 326.1 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.5/11.0 MB 326.6 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.5/11.0 MB 326.8 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.5/11.0 MB 326.8 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.0 MB 327.0 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.0 MB 327.5 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.0 MB 327.5 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.0 MB 327.9 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.6/11.0 MB 328.3 kB/s eta 0:00:11\n",
      "   --------------------------- ------------ 7.7/11.0 MB 328.6 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 329.2 kB/s eta 0:00:11\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 329.2 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.7/11.0 MB 329.9 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 330.3 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 330.5 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 331.2 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.8/11.0 MB 331.4 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 332.4 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 332.9 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 333.1 kB/s eta 0:00:10\n",
      "   ---------------------------- ----------- 7.9/11.0 MB 333.9 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 334.6 kB/s eta 0:00:10\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 335.2 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.0/11.0 MB 335.8 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 336.7 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 337.1 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.1/11.0 MB 338.3 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 339.2 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 339.8 kB/s eta 0:00:09\n",
      "   ----------------------------- ---------- 8.2/11.0 MB 340.4 kB/s eta 0:00:09\n",
      "   ------------------------------ --------- 8.3/11.0 MB 341.4 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.3/11.0 MB 342.3 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.3/11.0 MB 343.1 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.4/11.0 MB 343.7 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.4/11.0 MB 344.5 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.4/11.0 MB 345.5 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.5/11.0 MB 346.4 kB/s eta 0:00:08\n",
      "   ------------------------------ --------- 8.5/11.0 MB 347.1 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.6/11.0 MB 348.4 kB/s eta 0:00:08\n",
      "   ------------------------------- -------- 8.6/11.0 MB 349.2 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.6/11.0 MB 350.4 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.7/11.0 MB 351.6 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.7/11.0 MB 352.6 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.7/11.0 MB 353.2 kB/s eta 0:00:07\n",
      "   ------------------------------- -------- 8.7/11.0 MB 353.2 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.8/11.0 MB 354.3 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.8/11.0 MB 354.7 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.8/11.0 MB 355.3 kB/s eta 0:00:07\n",
      "   -------------------------------- ------- 8.9/11.0 MB 355.6 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 8.9/11.0 MB 356.6 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 8.9/11.0 MB 357.2 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 9.0/11.0 MB 357.7 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 9.0/11.0 MB 358.1 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 9.0/11.0 MB 358.9 kB/s eta 0:00:06\n",
      "   -------------------------------- ------- 9.1/11.0 MB 359.4 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 9.1/11.0 MB 360.2 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 9.1/11.0 MB 361.2 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 9.2/11.0 MB 361.7 kB/s eta 0:00:06\n",
      "   --------------------------------- ------ 9.2/11.0 MB 362.2 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 9.2/11.0 MB 363.0 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 9.2/11.0 MB 363.6 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 9.3/11.0 MB 364.7 kB/s eta 0:00:05\n",
      "   --------------------------------- ------ 9.3/11.0 MB 365.3 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.3/11.0 MB 366.0 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.3/11.0 MB 366.0 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 366.7 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 366.7 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 366.7 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 366.9 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 366.8 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 366.7 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 366.7 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 366.8 kB/s eta 0:00:05\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 367.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.5/11.0 MB 367.1 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 367.2 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 367.0 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 367.3 kB/s eta 0:00:04\n",
      "   ---------------------------------- ----- 9.6/11.0 MB 367.7 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.6/11.0 MB 367.6 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 367.9 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 368.0 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 368.4 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 368.9 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.7/11.0 MB 368.8 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 369.5 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 369.7 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 370.0 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.8/11.0 MB 370.3 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 370.6 kB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 9.9/11.0 MB 371.1 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 9.9/11.0 MB 371.7 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 9.9/11.0 MB 372.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.0/11.0 MB 372.5 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.0/11.0 MB 372.5 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.0/11.0 MB 373.1 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.0/11.0 MB 373.2 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.9 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.6 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.1/11.0 MB 373.3 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.0 MB 373.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.0 MB 373.4 kB/s eta 0:00:03\n",
      "   ------------------------------------ --- 10.2/11.0 MB 373.4 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.2/11.0 MB 373.1 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.2/11.0 MB 373.1 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.2/11.0 MB 372.7 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.2/11.0 MB 372.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.2/11.0 MB 372.5 kB/s eta 0:00:03\n",
      "   ------------------------------------- -- 10.3/11.0 MB 372.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 371.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 371.6 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 370.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 370.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 370.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 369.7 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.3/11.0 MB 369.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 369.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 369.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 369.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 367.8 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 367.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 367.2 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 366.4 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 365.5 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 364.9 kB/s eta 0:00:02\n",
      "   ------------------------------------- -- 10.4/11.0 MB 364.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.4/11.0 MB 364.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 364.3 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 363.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 363.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 363.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 363.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 362.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 361.7 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 361.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.5/11.0 MB 361.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 360.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 360.1 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 359.5 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 358.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 358.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 358.9 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 357.4 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 357.4 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 356.6 kB/s eta 0:00:02\n",
      "   -------------------------------------- - 10.6/11.0 MB 356.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.6/11.0 MB 356.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 355.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 355.2 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 354.5 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 353.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 353.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 10.7/11.0 MB 353.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 352.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.7/11.0 MB 352.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 351.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 351.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 351.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 351.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 350.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.8/11.0 MB 349.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 349.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 348.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 348.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 348.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 348.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 348.2 kB/s eta 0:00:01\n",
      "   ---------------------------------------  10.9/11.0 MB 347.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 347.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 347.3 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 346.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  11.0/11.0 MB 346.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 345.3 kB/s eta 0:00:00\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scikit-learn\n",
      "Successfully installed scikit-learn-1.5.1 threadpoolctl-3.5.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.30069751]\n",
      " [0.30069751 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Input texts\n",
    "text1 = 'Taj Mahal is a tourist place in India'\n",
    "text2 = 'Great Wall of China is a tourist place in china'\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the texts into TF-IDF vectors\n",
    "tfidf_matrix = vectorizer.fit_transform([text1, text2])\n",
    "\n",
    "# Calculate the cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "# Display the output\n",
    "print(cosine_sim)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "21. How to find soft cosine similarity of documents ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Compute the soft cosine similarity of the given documents\n",
    "\n",
    "\n",
    "Hint: Soft Cosine Similarity\n",
    "\n",
    "Input :\n",
    "\n",
    "doc_soup = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid. \"\n",
    "\n",
    "doc_noodles = \"Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"\n",
    "\n",
    "doc_dosa = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"\n",
    "\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin\"\n",
    "\n",
    "doc_election = \"President Trump says Putin had no political interference is the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election\"\n",
    "\n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career\"\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "\n",
    "0.5842470477718544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim import corpora\n",
    "from gensim.similarities import WordEmbeddingSimilarityIndex, SparseTermSimilarityMatrix\n",
    "import numpy as np\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Load the FastText model\n",
    "fasttext_model300 = api.load(\"fasttext-wiki-news-subwords-300\")\n",
    "\n",
    "# Sample documents\n",
    "doc_soup = \"Soup is a primarily liquid food, generally served warm or hot (but may be cool or cold), that is made by combining ingredients of meat or vegetables with stock, juice, water, or another liquid.\"\n",
    "doc_noodles = \"Noodles are a staple food in many cultures. They are made from unleavened dough which is stretched, extruded, or rolled flat and cut into one of a variety of shapes.\"\n",
    "doc_dosa = \"Dosa is a type of pancake from the Indian subcontinent, made from a fermented batter. It is somewhat similar to a crepe in appearance. Its main ingredients are rice and black gram.\"\n",
    "doc_trump = \"Mr. Trump became president after winning the political election. Though he lost the support of some republican friends, Trump is friends with President Putin.\"\n",
    "doc_election = \"President Trump says Putin had no political interference in the election outcome. He says it was a witchhunt by political parties. He claimed President Putin is a friend who had nothing to do with the election.\"\n",
    "doc_putin = \"Post elections, Vladimir Putin became President of Russia. President Putin had served as the Prime Minister earlier in his political career.\"\n",
    "\n",
    "# All documents\n",
    "documents = [doc_soup, doc_noodles, doc_dosa, doc_trump, doc_election, doc_putin]\n",
    "\n",
    "# Prepare a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Prepare the similarity index and similarity matrix\n",
    "similarity_index = WordEmbeddingSimilarityIndex(fasttext_model300)\n",
    "similarity_matrix = SparseTermSimilarityMatrix(similarity_index, dictionary)\n",
    "\n",
    "# Convert the sentences into bag-of-words vectors.\n",
    "sent_1 = dictionary.doc2bow(simple_preprocess(doc_trump))\n",
    "sent_2 = dictionary.doc2bow(simple_preprocess(doc_election))\n",
    "sent_3 = dictionary.doc2bow(simple_preprocess(doc_putin))\n",
    "sent_4 = dictionary.doc2bow(simple_preprocess(doc_soup))\n",
    "sent_5 = dictionary.doc2bow(simple_preprocess(doc_noodles))\n",
    "sent_6 = dictionary.doc2bow(simple_preprocess(doc_dosa))\n",
    "\n",
    "sentences = [sent_1, sent_2, sent_3, sent_4, sent_5, sent_6]\n",
    "\n",
    "# Convert BOW vectors to dense vectors using similarity matrix\n",
    "def bow_to_dense(bow, dictionary_size):\n",
    "    dense = np.zeros(dictionary_size)\n",
    "    for idx, freq in bow:\n",
    "        dense[idx] = freq\n",
    "    return dense\n",
    "\n",
    "# Compute soft cosine similarity manually\n",
    "def soft_cosine_sim(vec1, vec2, similarity_matrix):\n",
    "    similarity_score = vec1 @ similarity_matrix @ vec2\n",
    "    norm1 = np.sqrt(vec1 @ similarity_matrix @ vec1)\n",
    "    norm2 = np.sqrt(vec2 @ similarity_matrix @ vec2)\n",
    "    return similarity_score / (norm1 * norm2)\n",
    "\n",
    "# Calculate the soft cosine similarity between sent_1 and sent_2\n",
    "dense_1 = bow_to_dense(sent_1, len(dictionary))\n",
    "dense_2 = bow_to_dense(sent_2, len(dictionary))\n",
    "soft_cosine_similarity = soft_cosine_sim(dense_1, dense_2, similarity_matrix)\n",
    "\n",
    "# Output the soft cosine similarity\n",
    "print(f\"Soft Cosine Similarity between Trump and Election: {soft_cosine_similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "22. How to find similar words using pre-trained Word2Vec?\n",
    "\n",
    "Q. Find all similiar words to “amazing” using Google news Word2Vec.\n",
    "\n",
    "Desired Output:\n",
    "\n",
    "#> [('incredible', 0.90),\n",
    "\n",
    "#> ('awesome', 0.82),\n",
    "\n",
    "#> ('unbelievable', 0.82),\n",
    "\n",
    "#> ('fantastic', 0.77),\n",
    "\n",
    "#> ('phenomenal', 0.76),\n",
    "\n",
    "#> ('astounding', 0.73),\n",
    "\n",
    "#> ('wonderful', 0.72),\n",
    "\n",
    "#> ('unbelieveable', 0.71),\n",
    "\n",
    "#> ('remarkable', 0.70),\n",
    "\n",
    "#> ('marvelous', 0.70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "\n",
    "# Load the Google News Word2Vec model\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Find similar words to \"amazing\"\n",
    "similar_words = model.most_similar(\"amazing\", topn=10)\n",
    "\n",
    "# Output the similar words\n",
    "print(similar_words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "23. How to compute Word mover distance?\n",
    "\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Compute the word mover distance between given two texts\n",
    "\n",
    "Input :\n",
    "\n",
    "\n",
    "sentence_orange = 'Oranges are my favorite fruit'\n",
    "\n",
    "sent=\"apples are not my favorite\"\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "\n",
    " 5.378"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load the pre-trained Word2Vec model\n",
    "model = api.load(\"word2vec-google-news-300\")\n",
    "\n",
    "# Define the sentences\n",
    "sentence_orange = \"Oranges are my favorite fruit\"\n",
    "sentence_apple = \"Apples are not my favorite\"\n",
    "\n",
    "# Preprocess the sentences (tokenization and lowering)\n",
    "sentence_orange = sentence_orange.lower().split()\n",
    "sentence_apple = sentence_apple.lower().split()\n",
    "\n",
    "# Compute the Word Mover's Distance\n",
    "distance = model.wmdistance(sentence_orange, sentence_apple)\n",
    "\n",
    "# Output the distance\n",
    "print(f\"Word Mover's Distance: {distance:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "24. How to replace all the pronouns in a text with their respective object names\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Replace the pronouns in below text by the respective object nmaes\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\" My sister has a dog and she loves him\"\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "\n",
    "[My sister,she]\n",
    "\n",
    "[a dog ,him ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('My sister', 'she'), ('a dog', 'him')]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Sample text\n",
    "text = \"My sister has a dog and she loves him.\"\n",
    "\n",
    "# Define the pronouns and their corresponding objects\n",
    "pronouns_to_objects = {\n",
    "    \"she\": \"My sister\",\n",
    "    \"him\": \"a dog\"\n",
    "}\n",
    "\n",
    "# Find and replace pronouns, while capturing objects\n",
    "def replace_pronouns(text, pronouns_to_objects):\n",
    "    pronoun_matches = []\n",
    "    for pronoun, obj in pronouns_to_objects.items():\n",
    "        # Use a regex to find pronouns in the text\n",
    "        matches = re.findall(rf'\\b{pronoun}\\b', text, flags=re.IGNORECASE)\n",
    "        if matches:\n",
    "            pronoun_matches.append((obj, pronoun))\n",
    "            # Replace the pronoun with a placeholder to avoid double replacements\n",
    "            text = re.sub(rf'\\b{pronoun}\\b', 'PLACEHOLDER', text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Restore the original objects in the text\n",
    "    for obj, _ in pronoun_matches:\n",
    "        text = re.sub('PLACEHOLDER', obj, text, count=1)\n",
    "    \n",
    "    return pronoun_matches\n",
    "\n",
    "# Get the pronoun-object pairs\n",
    "pairs = replace_pronouns(text, pronouns_to_objects)\n",
    "print(pairs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "25. How to extract topic keywords using LSA?\n",
    "\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the topic keywords from the given texts using LSA(Latent Semantic Analysis )\n",
    "\n",
    "Input :\n",
    "\n",
    "texts= [\"\"\"It's all about travel. I travel a lot.  those who do not travel read only a page.” – said Saint Augustine. He was a great travel person. Travelling can teach you more than any university course. You learn about the culture of the country you visit. If you talk to locals, you will likely learn about their thinking, habits, traditions and history as well.If you travel, you will not only learn about foreign cultures, but about your own as well. You will notice the cultural differences, and will find out what makes your culture unique. After retrurning from a long journey, you will see your country with new eyes.\"\"\",\n",
    "        \"\"\" You can learn a lot about yourself through travelling. You can observe how you feel beeing far from your country. You will find out how you feel about your homeland.You should travel You will realise how you really feel about foreign people. You will find out how much you know/do not know about the world. You will be able to observe how you react in completely new situations. You will test your language, orientational and social skills. You will not be the same person after returning home.During travelling you will meet people that are very different from you. If you travel enough, you will learn to accept and appreciate these differences. Traveling makes you more open and accepting.\"\"\",\n",
    "        \"\"\"Some of my most cherished memories are from the times when I was travelling. If you travel, you can experience things that you could never experience at home. You may see beautiful places and landscapes that do not exist where you live. You may meet people that will change your life, and your thingking. You may try activities that you have never tried before.Travelling will inevitably make you more independent and confident. You will realise that you can cope with a lot of unexpected situations. You will realise that you can survive without all that help that is always available for you at home. You will likely find out that you are much stronger and braver than you have expected.\"\"\",\n",
    "        \"\"\"If you travel, you may learn a lot of useful things. These things can be anything from a new recepie, to a new, more effective solution to an ordinary problem or a new way of creating something.Even if you go to a country where they speak the same language as you, you may still learn some new words and expressions that are only used there. If you go to a country where they speak a different language, you will learn even more.\"\"\",\n",
    "        \"\"\"After arriving home from a long journey, a lot of travellers experience that they are much more motivated than they were before they left. During your trip you may learn things that you will want to try at home as well. You may want to test your new skills and knowledge. Your experiences will give you a lot of energy.During travelling you may experience the craziest, most exciting things, that will eventually become great stories that you can tell others. When you grow old and look back at your life and all your travel experiences, you will realise how much you have done in your life and your life was not in vain. It can provide you with happiness and satisfaction for the rest of your life.\"\"\",\n",
    "        \"\"\"The benefits of travel are not just a one-time thing: travel changes you physically and psychologically. Having little time or money isn't a valid excuse. You can travel for cheap very easily. If you have a full-time job and a family, you can still travel on the weekends or holidays, even with a baby. travel  more is likely to have a tremendous impact on your mental well-being, especially if you're no used to going out of your comfort zone. Trust me: travel more and your doctor will be happy. Be sure to get in touch with your physician, they might recommend some medication to accompany you in your travels, especially if you're heading to regions of the globe with potentially dangerous diseases.\"\"\",\n",
    "        \"\"\"Sure, you probably feel comfortable where you are, but that is just a fraction of the world! If you are a student, take advantage of programs such as Erasmus to get to know more people, experience and understand their culture. Dare traveling to regions you have a skeptical opinion about. I bet that you will change your mind and realize that everything is not so bad abroad.\"\"\",\n",
    "        \"\"\" So, travel makes you cherish life. Let's travel more . Share your travel diaries with us too\"\"\"\n",
    "        ]\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "\n",
    "#> Topic 0: \n",
    "\n",
    "#> learn new life travelling country feel  \n",
    "\n",
    "#> Topic 1: \n",
    "\n",
    "#> life cherish diaries let share experience  \n",
    "\n",
    "#> Topic 2: \n",
    "\n",
    "#> feel know time people just regions  \n",
    "\n",
    "#> Topic 3: \n",
    "\n",
    "#> time especially cherish diaries let share  \n",
    "\n",
    "..(truncated).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "learn new life travelling country feel things \n",
      "Topic 1: \n",
      "life cherish diaries let share experience home \n",
      "Topic 2: \n",
      "feel know time people just regions sure \n",
      "Topic 3: \n",
      "time especially cherish diaries let share life \n",
      "Topic 4: \n",
      "cherish diaries let share makes feel know \n",
      "Topic 5: \n",
      "culture augustine course cultural cultures eyes habits \n",
      "Topic 6: \n",
      "experiences want life things advantage bad bet \n",
      "Topic 7: \n",
      "observe feel want experiences skills test know \n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Input texts\n",
    "texts = [\n",
    "    \"\"\"It's all about travel. I travel a lot.  those who do not travel read only a page.” – said Saint Augustine. He was a great travel person. Travelling can teach you more than any university course. You learn about the culture of the country you visit. If you talk to locals, you will likely learn about their thinking, habits, traditions and history as well.If you travel, you will not only learn about foreign cultures, but about your own as well. You will notice the cultural differences, and will find out what makes your culture unique. After retrurning from a long journey, you will see your country with new eyes.\"\"\",\n",
    "    \"\"\"You can learn a lot about yourself through travelling. You can observe how you feel beeing far from your country. You will find out how you feel about your homeland.You should travel You will realise how you really feel about foreign people. You will find out how much you know/do not know about the world. You will be able to observe how you react in completely new situations. You will test your language, orientational and social skills. You will not be the same person after returning home.During travelling you will meet people that are very different from you. If you travel enough, you will learn to accept and appreciate these differences. Traveling makes you more open and accepting.\"\"\",\n",
    "    \"\"\"Some of my most cherished memories are from the times when I was travelling. If you travel, you can experience things that you could never experience at home. You may see beautiful places and landscapes that do not exist where you live. You may meet people that will change your life, and your thingking. You may try activities that you have never tried before.Travelling will inevitably make you more independent and confident. You will realise that you can cope with a lot of unexpected situations. You will realise that you can survive without all that help that is always available for you at home. You will likely find out that you are much stronger and braver than you have expected.\"\"\",\n",
    "    \"\"\"If you travel, you may learn a lot of useful things. These things can be anything from a new recepie, to a new, more effective solution to an ordinary problem or a new way of creating something.Even if you go to a country where they speak the same language as you, you may still learn some new words and expressions that are only used there. If you go to a country where they speak a different language, you will learn even more.\"\"\",\n",
    "    \"\"\"After arriving home from a long journey, a lot of travellers experience that they are much more motivated than they were before they left. During your trip you may learn things that you will want to try at home as well. You may want to test your new skills and knowledge. Your experiences will give you a lot of energy.During travelling you may experience the craziest, most exciting things, that will eventually become great stories that you can tell others. When you grow old and look back at your life and all your travel experiences, you will realise how much you have done in your life and your life was not in vain. It can provide you with happiness and satisfaction for the rest of your life.\"\"\",\n",
    "    \"\"\"The benefits of travel are not just a one-time thing: travel changes you physically and psychologically. Having little time or money isn't a valid excuse. You can travel for cheap very easily. If you have a full-time job and a family, you can still travel on the weekends or holidays, even with a baby. travel more is likely to have a tremendous impact on your mental well-being, especially if you're no used to going out of your comfort zone. Trust me: travel more and your doctor will be happy. Be sure to get in touch with your physician, they might recommend some medication to accompany you in your travels, especially if you're heading to regions of the globe with potentially dangerous diseases.\"\"\",\n",
    "    \"\"\"Sure, you probably feel comfortable where you are, but that is just a fraction of the world! If you are a student, take advantage of programs such as Erasmus to get to know more people, experience and understand their culture. Dare traveling to regions you have a skeptical opinion about. I bet that you will change your mind and realize that everything is not so bad abroad.\"\"\",\n",
    "    \"\"\"So, travel makes you cherish life. Let's travel more. Share your travel diaries with us too\"\"\"\n",
    "]\n",
    "\n",
    "# Importing the Tf-idf vectorizer from sklearn\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=1000, max_df=0.5, smooth_idf=True)\n",
    "\n",
    "# Transforming the tokens into the matrix form through .fit_transform()\n",
    "matrix = vectorizer.fit_transform(texts)\n",
    "\n",
    "# SVD represent documents and terms in vectors\n",
    "SVD_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=100, random_state=122)\n",
    "SVD_model.fit(matrix)\n",
    "\n",
    "# Getting the terms\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Iterating through each topic\n",
    "for i, comp in enumerate(SVD_model.components_):\n",
    "    terms_comp = zip(terms, comp)\n",
    "    # Sorting the 7 most important terms\n",
    "    sorted_terms = sorted(terms_comp, key=lambda x: x[1], reverse=True)[:7]\n",
    "    print(f\"Topic {i}: \")\n",
    "    # Printing the terms of a topic\n",
    "    for t in sorted_terms:\n",
    "        print(t[0], end=' ')\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "26. How to extract topic Keywords using LDA ?\n",
    "\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the the topics from the given texts with the help of LDA(Latent dirichlet algorithm)\n",
    "\n",
    "Input :\n",
    "\n",
    "texts= [\"\"\"It's all about travel. I travel a lot.  those who do not travel read only a page.” – said Saint Augustine. He was a great travel person. Travelling can teach you more than any university course. You learn about the culture of the country you visit. If you talk to locals, you will likely learn about their thinking, habits, traditions and history as well.If you travel, you will not only learn about foreign cultures, but about your own as well. You will notice the cultural differences, and will find out what makes your culture unique. After retrurning from a long journey, you will see your country with new eyes.\"\"\",\n",
    "        \"\"\" You can learn a lot about yourself through travelling. You can observe how you feel beeing far from your country. You will find out how you feel about your homeland.You should travel You will realise how you really feel about foreign people. You will find out how much you know/do not know about the world. You will be able to observe how you react in completely new situations. You will test your language, orientational and social skills. You will not be the same person after returning home.During travelling you will meet people that are very different from you. If you travel enough, you will learn to accept and appreciate these differences. Traveling makes you more open and accepting.\"\"\",\n",
    "        \"\"\"Some of my most cherished memories are from the times when I was travelling. If you travel, you can experience things that you could never experience at home. You may see beautiful places and landscapes that do not exist where you live. You may meet people that will change your life, and your thingking. You may try activities that you have never tried before.Travelling will inevitably make you more independent and confident. You will realise that you can cope with a lot of unexpected situations. You will realise that you can survive without all that help that is always available for you at home. You will likely find out that you are much stronger and braver than you have expected.\"\"\",\n",
    "        \"\"\"If you travel, you may learn a lot of useful things. These things can be anything from a new recepie, to a new, more effective solution to an ordinary problem or a new way of creating something.Even if you go to a country where they speak the same language as you, you may still learn some new words and expressions that are only used there. If you go to a country where they speak a different language, you will learn even more.\"\"\",\n",
    "        \"\"\"After arriving home from a long journey, a lot of travellers experience that they are much more motivated than they were before they left. During your trip you may learn things that you will want to try at home as well. You may want to test your new skills and knowledge. Your experiences will give you a lot of energy.During travelling you may experience the craziest, most exciting things, that will eventually become great stories that you can tell others. When you grow old and look back at your life and all your travel experiences, you will realise how much you have done in your life and your life was not in vain. It can provide you with happiness and satisfaction for the rest of your life.\"\"\",\n",
    "        \"\"\"The benefits of travel are not just a one-time thing: travel changes you physically and psychologically. Having little time or money isn't a valid excuse. You can travel for cheap very easily. If you have a full-time job and a family, you can still travel on the weekends or holidays, even with a baby. travel  more is likely to have a tremendous impact on your mental well-being, especially if you're no used to going out of your comfort zone. Trust me: travel more and your doctor will be happy. Be sure to get in touch with your physician, they might recommend some medication to accompany you in your travels, especially if you're heading to regions of the globe with potentially dangerous diseases.\"\"\",\n",
    "        \"\"\"Sure, you probably feel comfortable where you are, but that is just a fraction of the world! If you are a student, take advantage of programs such as Erasmus to get to know more people, experience and understand their culture. Dare traveling to regions you have a skeptical opinion about. I bet that you will change your mind and realize that everything is not so bad abroad.\"\"\",\n",
    "        \"\"\" So, travel makes you cherish life. Let's travel more . Share your travel diaries with us too\"\"\"\n",
    "        ]\n",
    "        \n",
    "Desired Output :\n",
    "\n",
    "[(0, '0.068*\"travel\" + 0.044*\"learn\" + 0.027*\"country\" + 0.027*\"If\" + 0.026*\"find\"'), (1, '0.054*\"may\" + 0.036*\"realise\" + 0.036*\"home\" + 0.036*\"experience\" + 0.036*\"never\"'), (2, '0.047*\"may\" + 0.044*\"life\" + 0.039*\"new\" + 0.036*\"things\" + 0.032*\"learn\"'), (3, '0.031*\"If\" + 0.031*\"people\" + 0.031*\"I\" + 0.031*\"world\" + 0.031*\"know\"'), (4, '0.085*\"travel\" + 0.042*\"\\'\" + 0.042*\"-\" + 0.042*\"time\" + 0.028*\"especially\"')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['(0, \\'0.004*\"travel\" + 0.004*\"learn\" + 0.004*\"life\" + 0.004*\"country\" + 0.004*\"new\"\\')', '(1, \\'0.039*\"may\" + 0.031*\"new\" + 0.024*\"learn\" + 0.024*\"things\" + 0.016*\"realise\"\\')', '(2, \\'0.053*\"travel\" + 0.021*\"feel\" + 0.014*\"people\" + 0.014*\"find\" + 0.014*\"travelling\"\\')', '(3, \\'0.060*\"travel\" + 0.024*\"learn\" + 0.024*\"culture\" + 0.016*\"country\" + 0.016*\"makes\"\\')', '(4, \\'0.041*\"life\" + 0.031*\"may\" + 0.021*\"lot\" + 0.021*\"experience\" + 0.021*\"much\"\\')']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import gensim\n",
    "from gensim import models, corpora\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define stopwords and punctuations\n",
    "my_stopwords = set(stopwords.words('english'))\n",
    "punctuations = ['.', '!', ',', '\"', \"You\", \"I\"]\n",
    "\n",
    "# Prepare a list containing lists of tokens for each text\n",
    "all_tokens = []\n",
    "for text in texts:\n",
    "    tokens = []\n",
    "    raw = word_tokenize(text)\n",
    "    for token in raw:\n",
    "        if token.lower() not in my_stopwords and token not in punctuations:\n",
    "            tokens.append(token.lower())\n",
    "    all_tokens.append(tokens)\n",
    "\n",
    "# Creating a gensim dictionary and the document-term matrix\n",
    "dictionary = corpora.Dictionary(all_tokens)\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in all_tokens]\n",
    "\n",
    "# Building the LDA model\n",
    "lda_model = models.LdaModel(doc_term_matrix, num_topics=5, id2word=dictionary, passes=40)\n",
    "\n",
    "# Function to format the topics\n",
    "def format_topic_words(topic):\n",
    "    topic_id, words = topic\n",
    "    formatted_words = ' + '.join([f'{weight:.3f}*\"{\" \".join(word.split())}\"' for word, weight in lda_model.show_topic(topic_id, topn=5)])\n",
    "    return f'({topic_id}, \\'{formatted_words}\\')'\n",
    "\n",
    "# Print topics in the desired format\n",
    "topics = [format_topic_words(topic) for topic in lda_model.show_topics(num_topics=5, num_words=5, formatted=False)]\n",
    "print(topics)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "27. How to extract topic keywords using NMF?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the the topics from the given texts with the help of NMF(Non-negative Matrix Factorization method)\n",
    "\n",
    "Input :\n",
    "\n",
    "texts= [\"\"\"It's all about travel. I travel a lot.  those who do not travel read only a page.” – said Saint Augustine. He was a great travel person. Travelling can teach you more than any university course. You learn about the culture of the country you visit. If you talk to locals, you will likely learn about their thinking, habits, traditions and history as well.If you travel, you will not only learn about foreign cultures, but about your own as well. You will notice the cultural differences, and will find out what makes your culture unique. After retrurning from a long journey, you will see your country with new eyes.\"\"\",\n",
    "        \"\"\" You can learn a lot about yourself through travelling. You can observe how you feel beeing far from your country. You will find out how you feel about your homeland.You should travel You will realise how you really feel about foreign people. You will find out how much you know/do not know about the world. You will be able to observe how you react in completely new situations. You will test your language, orientational and social skills. You will not be the same person after returning home.During travelling you will meet people that are very different from you. If you travel enough, you will learn to accept and appreciate these differences. Traveling makes you more open and accepting.\"\"\",\n",
    "        \"\"\"Some of my most cherished memories are from the times when I was travelling. If you travel, you can experience things that you could never experience at home. You may see beautiful places and landscapes that do not exist where you live. You may meet people that will change your life, and your thingking. You may try activities that you have never tried before.Travelling will inevitably make you more independent and confident. You will realise that you can cope with a lot of unexpected situations. You will realise that you can survive without all that help that is always available for you at home. You will likely find out that you are much stronger and braver than you have expected.\"\"\",\n",
    "        \"\"\"If you travel, you may learn a lot of useful things. These things can be anything from a new recepie, to a new, more effective solution to an ordinary problem or a new way of creating something.Even if you go to a country where they speak the same language as you, you may still learn some new words and expressions that are only used there. If you go to a country where they speak a different language, you will learn even more.\"\"\",\n",
    "        \"\"\"After arriving home from a long journey, a lot of travellers experience that they are much more motivated than they were before they left. During your trip you may learn things that you will want to try at home as well. You may want to test your new skills and knowledge. Your experiences will give you a lot of energy.During travelling you may experience the craziest, most exciting things, that will eventually become great stories that you can tell others. When you grow old and look back at your life and all your travel experiences, you will realise how much you have done in your life and your life was not in vain. It can provide you with happiness and satisfaction for the rest of your life.\"\"\",\n",
    "        \"\"\"The benefits of travel are not just a one-time thing: travel changes you physically and psychologically. Having little time or money isn't a valid excuse. You can travel for cheap very easily. If you have a full-time job and a family, you can still travel on the weekends or holidays, even with a baby. travel  more is likely to have a tremendous impact on your mental well-being, especially if you're no used to going out of your comfort zone. Trust me: travel more and your doctor will be happy. Be sure to get in touch with your physician, they might recommend some medication to accompany you in your travels, especially if you're heading to regions of the globe with potentially dangerous diseases.\"\"\",\n",
    "        \"\"\"Sure, you probably feel comfortable where you are, but that is just a fraction of the world! If you are a student, take advantage of programs such as Erasmus to get to know more people, experience and understand their culture. Dare traveling to regions you have a skeptical opinion about. I bet that you will change your mind and realize that everything is not so bad abroad.\"\"\",\n",
    "        \"\"\" So, travel makes you cherish life. Let's travel more . Share your travel diaries with us too\"\"\"\n",
    "        ]\n",
    "  \n",
    "Desired Output:\n",
    "\n",
    " Topic 0:\n",
    " [('new', 0.6329770846997606), ('learn', 0.49810389825931783), ('speak', 0.47477546214544547), ('language', 0.43443029670471806), ('country', 0.36653909845383115), ('things', 0.3433223730439043)]\n",
    " Topic 1:\n",
    " [('life', 0.34063551920788737), ('home', 0.31402014643240667), ('experience', 0.3025841622571281), ('realise', 0.24642870225288288), ('travelling', 0.2180915553025073), ('things', 0.2076347895889257)]\n",
    " Topic 2:\n",
    " [('feel', 0.3462484013922396), ('know', 0.28400088182008115), ('people', 0.2431266883545085), ('world', 0.22169277349692076), ('traveling', 0.22169277349692076), ('bet', 0.18671974365540467)]\n",
    "...(truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "[('may', 0.6260182365513983), ('life', 0.49087553673657497), ('home', 0.4309487490015614), ('experience', 0.41831410560918203), ('realise', 0.3331006258954924), ('much', 0.3164743255857419)]\n",
      "Topic 1:\n",
      "[('travel', 0.6411986360896813), ('let', 0.45551766100712593), ('cherish', 0.45551766100712593), ('share', 0.45551766100712593), ('diaries', 0.45551766100712593), ('us', 0.45551766100712593)]\n",
      "Topic 2:\n",
      "[('feel', 0.2395569139014655), ('know', 0.21610082226871247), ('take', 0.1991453312463441), ('mind', 0.1991453312463441), ('everything', 0.1991453312463441), ('programs', 0.1991453312463441)]\n",
      "Topic 3:\n",
      "[('learn', 0.46772185742575806), ('new', 0.3717416459336377), ('country', 0.33871184062186815), ('travel', 0.26143374642975514), ('language', 0.23591527120461606), ('go', 0.21103820536880719)]\n",
      "Topic 4:\n",
      "[('time', 0.44521599787181093), ('travel', 0.4058113688622357), ('re', 0.2968106652478739), ('especially', 0.2968106652478739), ('holidays', 0.14840533262393696), ('touch', 0.14840533262393696)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import NMF\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK resources if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define stopwords and punctuations\n",
    "my_stopwords = set(stopwords.words('english'))\n",
    "punctuations = ['.', '!', ',', '\"', \"You\", \"I\"]\n",
    "\n",
    "# Prepare the texts for NMF by removing stopwords and punctuations\n",
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [token.lower() for token in tokens if token.lower() not in my_stopwords and token not in punctuations]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "processed_texts = [preprocess_text(text) for text in texts]\n",
    "\n",
    "# Create a TF-IDF vectorizer and transform the texts into a TF-IDF matrix\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(processed_texts)\n",
    "\n",
    "# Build and train the NMF model\n",
    "num_topics = 5\n",
    "nmf_model = NMF(n_components=num_topics, random_state=1).fit(tfidf_matrix)\n",
    "\n",
    "# Function to get the top words for each topic\n",
    "def get_top_words_for_topic(model, vectorizer, n_words=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topics = {}\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        top_words_idx = topic.argsort()[:-n_words - 1:-1]\n",
    "        top_words = [(feature_names[i], topic[i]) for i in top_words_idx]\n",
    "        topics[f'Topic {topic_idx}'] = top_words\n",
    "    return topics\n",
    "\n",
    "# Print the topics with top words and their weights\n",
    "topics = get_top_words_for_topic(nmf_model, vectorizer, n_words=6)\n",
    "for topic, words in topics.items():\n",
    "    print(f\"{topic}:\")\n",
    "    print(words)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "28. How to classify a text as positive/negative sentiment\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Detect if a text is positive or negative sentiment\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"It was a very pleasant day\"\n",
    "\n",
    "Desired Output:\n",
    "\n",
    " Sentiment(polarity=0.9533333333333333, subjectivity=1.0)\n",
    " \n",
    "Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.9533333333333333, subjectivity=1.0)\n",
      "Positive\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "# Input text\n",
    "text = \"It was a very pleasant day\"\n",
    "\n",
    "# Create a TextBlob object\n",
    "blob = TextBlob(text)\n",
    "\n",
    "# Get sentiment polarity and subjectivity\n",
    "sentiment = blob.sentiment\n",
    "\n",
    "# Print sentiment analysis result\n",
    "print(f\"Sentiment(polarity={sentiment.polarity}, subjectivity={sentiment.subjectivity})\")\n",
    "\n",
    "# Determine sentiment category\n",
    "if sentiment.polarity > 0:\n",
    "    print(\"Positive\")\n",
    "elif sentiment.polarity < 0:\n",
    "    print(\"Negative\")\n",
    "else:\n",
    "    print(\"Neutral\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31. How to represent the document using Doc2Vec model?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Represent a text document in the form a vector\n",
    "\n",
    "Input :\n",
    "\n",
    "texts= [\" Photography is an excellent hobby to pursue \",\n",
    "        \" Photographers usually develop patience, calmnesss\"\n",
    "        \" You can try Photography with any good mobile too\"]\n",
    "Desired Output:\n",
    "\n",
    "array([ 2.6586275e-03,  3.2867077e-03, -2.0473711e-03,  6.0251489e-04,\n",
    "       -1.5340233e-03,  1.5060971e-03,  1.0988972e-03,  1.0712545e-03,\n",
    "       -4.3745534e-03, -4.0448168e-03, -1.8953394e-04, -2.0953947e-04,\n",
    "       -3.3285557e-03,  1.0409033e-03, -8.5728493e-04,  4.5999791e-03,\n",
    "        ...(truncated).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 vector:\n",
      "[-0.00552774 -0.00632707 -0.00991534  0.00871942  0.00378376  0.00017534\n",
      " -0.00978669 -0.00519287 -0.00980836  0.00211298  0.00269665  0.00474669\n",
      " -0.00456028 -0.00328665 -0.00293795 -0.00877006  0.00205352  0.00931798\n",
      " -0.00969689 -0.003582   -0.00388898  0.00257249 -0.00568019  0.00293575\n",
      "  0.00561399 -0.00811775 -0.00859232 -0.01009927  0.00489523 -0.0092975\n",
      "  0.00590859  0.00671792 -0.00642977 -0.00480984 -0.00140921  0.00183397\n",
      " -0.0016486  -0.0088164  -0.00385845  0.00147649 -0.00179654 -0.00719068\n",
      "  0.00443883 -0.0086527   0.00271313 -0.00468701  0.00055973 -0.00192451\n",
      "  0.00546457 -0.0083723  -0.00249849 -0.00024452 -0.00683281 -0.00685367\n",
      " -0.0020628   0.00922079 -0.00120523  0.00376494 -0.00584872  0.0089819\n",
      "  0.00321291  0.00969274  0.0047212  -0.00424678  0.00223223 -0.00434865\n",
      "  0.00592807  0.00216491 -0.00233879 -0.00590106 -0.00831511 -0.00070268\n",
      " -0.00906123 -0.00923003 -0.00783266  0.00217977 -0.00665091 -0.00797614\n",
      "  0.00200446  0.00187898  0.00835538  0.00488221 -0.00970982 -0.00037938\n",
      "  0.00779473  0.00299144  0.00275167 -0.00507844  0.00645378  0.00169052\n",
      " -0.00792802  0.00698123 -0.01008812 -0.00810432 -0.00479394  0.0103158\n",
      "  0.00309486 -0.00215173  0.00930927  0.00235768]\n",
      "\n",
      "Document 1 vector:\n",
      "[-0.00570845 -0.00333405 -0.00599721  0.00383251 -0.00674497 -0.00207789\n",
      " -0.0010947   0.00733325  0.0066452   0.0034489  -0.0001566  -0.00466589\n",
      " -0.00209007 -0.00548963  0.00901408 -0.00864636 -0.01003951 -0.00072381\n",
      "  0.00357723  0.00806051  0.00887303  0.00623805 -0.00624162  0.00881407\n",
      " -0.00954299  0.00069682 -0.00678491 -0.00084435  0.00264121 -0.00779158\n",
      "  0.00399918  0.00139617 -0.0005048   0.00610984 -0.00445555 -0.00160208\n",
      "  0.00096645  0.0027997  -0.00887402 -0.00520962  0.00801087  0.00094292\n",
      "  0.00382581 -0.00939608 -0.00198448  0.00213837  0.00256039  0.00901265\n",
      "  0.00031575 -0.00487836 -0.00345485  0.00958776  0.00740678 -0.00907512\n",
      " -0.0036696   0.00564835  0.00092119  0.00891784 -0.00591738 -0.00300791\n",
      "  0.00853866  0.00565625  0.00892815 -0.00319174  0.00230345 -0.00683785\n",
      " -0.00586531 -0.00578669 -0.00839043 -0.00223232  0.0034326  -0.00157546\n",
      "  0.00295389  0.00510835  0.00752686  0.00256584  0.0078677  -0.00408609\n",
      " -0.00486564 -0.00125538  0.00589504  0.0048917  -0.00843986 -0.00294945\n",
      " -0.00808832  0.00889398 -0.00194834 -0.00017951  0.00865756  0.00184536\n",
      " -0.00759406  0.00683028  0.00458391  0.00797459 -0.00386569  0.00459581\n",
      "  0.00488348 -0.00415246  0.00234907  0.00533204]\n",
      "\n",
      "Document 2 vector:\n",
      "[-8.2493834e-03 -9.6384222e-03  8.4981928e-03 -4.1609858e-03\n",
      "  9.9902013e-03 -2.8283948e-03  9.8239575e-03 -5.9865159e-03\n",
      "  3.2858655e-03  4.5245355e-03 -8.8880314e-03  5.2996078e-03\n",
      " -6.9301552e-03 -3.9012581e-03  4.8141945e-03  9.5545985e-03\n",
      " -2.9878384e-03 -3.0234063e-03  4.5878289e-05 -7.2935864e-04\n",
      " -9.9204825e-03 -7.9828650e-03  5.8244569e-03  7.5448374e-03\n",
      " -4.9973452e-03  3.3483291e-03 -1.5968481e-03  3.3836297e-03\n",
      " -6.2697795e-03  2.7198347e-03 -4.9012997e-03 -6.7970762e-03\n",
      "  8.7100575e-03 -8.1996769e-03 -3.2052933e-03  4.6901526e-03\n",
      " -8.6242156e-03 -5.0848532e-03  5.1784556e-04 -6.1985156e-03\n",
      "  9.2807636e-03  9.1327503e-03  7.7634654e-03  2.8218662e-03\n",
      " -5.0692554e-03 -5.4505281e-04 -2.1140121e-03  6.3403104e-03\n",
      " -6.9599273e-03 -9.1596255e-03 -1.0222129e-02 -8.2804924e-03\n",
      " -6.6674454e-03 -2.6985593e-03 -2.5208143e-03  6.8758144e-03\n",
      "  4.6585468e-03  5.5513680e-03  2.5870702e-03  2.2519715e-03\n",
      "  4.9391510e-03  9.2891948e-03  5.8026407e-03  2.0076379e-03\n",
      " -2.0965668e-03  5.3493385e-03  7.4184085e-03  9.6788285e-03\n",
      "  6.4860219e-03  4.6766899e-03 -1.0328605e-02  3.6631692e-03\n",
      " -2.0480056e-03  3.9369599e-03  6.5903952e-03 -2.2775200e-03\n",
      " -8.9364704e-03 -2.5745363e-03 -5.2978341e-03 -3.9742431e-03\n",
      " -5.6759170e-03  5.4779509e-03  3.5794798e-04  1.4024766e-04\n",
      " -4.8990962e-03  1.0146547e-02  6.3230615e-04 -2.7959556e-03\n",
      " -9.2493165e-03  2.9093011e-03 -7.9883346e-03 -4.5485962e-03\n",
      " -9.5186578e-03  1.4247844e-03  8.4676603e-03  6.3526346e-03\n",
      " -3.2088198e-03 -1.3181206e-03  1.0227807e-02 -6.8085864e-03]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Input texts\n",
    "texts = [\n",
    "    \"Photography is an excellent hobby to pursue\",\n",
    "    \"Photographers usually develop patience, calmness\",\n",
    "    \"You can try Photography with any good mobile too\"\n",
    "]\n",
    "\n",
    "# Tokenize and preprocess the texts\n",
    "tokenized_texts = [word_tokenize(text.lower()) for text in texts]\n",
    "\n",
    "# Create TaggedDocument objects\n",
    "tagged_data = [TaggedDocument(words=text, tags=[str(i)]) for i, text in enumerate(tokenized_texts)]\n",
    "\n",
    "# Train the Doc2Vec model\n",
    "model = Doc2Vec(vector_size=100, window=5, min_count=1, workers=4, epochs=40)\n",
    "model.build_vocab(tagged_data)\n",
    "model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Infer document vectors\n",
    "doc_vectors = [model.dv[str(i)] for i in range(len(texts))]\n",
    "\n",
    "for i, vec in enumerate(doc_vectors):\n",
    "    print(f\"Document {i} vector:\")\n",
    "    print(vec)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "32. How to extract the TF-IDF Matrix ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the TF-IDF (Term Frequency -Inverse Document Frequency) Matrix for the given list of text documents\n",
    "\n",
    "Input :\n",
    "\n",
    "text_documents=['Painting is a hobby for many , passion for some',\n",
    "                'My hobby is coin collection'\n",
    "                'I do some Painting every now and then']\n",
    "Desired Output:\n",
    "\n",
    " \n",
    "(0, 13)\t0.2511643891128359\n",
    "(0, 12)\t0.35300278529739293\n",
    "(0, 8)\t0.35300278529739293\n",
    "(0, 5)\t0.7060055705947859\n",
    "(0, 6)\t0.2511643891128359\n",
    "(0, 7)\t0.2511643891128359\n",
    "...(truncated).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix:\n",
      "Document 0:\n",
      "(0, 5)\t0.6936421729446067\n",
      "(0, 6)\t0.2637663757328758\n",
      "(0, 7)\t0.2637663757328758\n",
      "(0, 8)\t0.34682108647230336\n",
      "(0, 11)\t0.2637663757328758\n",
      "(0, 12)\t0.34682108647230336\n",
      "(0, 13)\t0.2637663757328758\n",
      "\n",
      "Document 1:\n",
      "(1, 1)\t0.49047908420610337\n",
      "(1, 2)\t0.49047908420610337\n",
      "(1, 6)\t0.3730219858594306\n",
      "(1, 7)\t0.3730219858594306\n",
      "(1, 9)\t0.49047908420610337\n",
      "\n",
      "Document 2:\n",
      "(2, 0)\t0.40301621080355077\n",
      "(2, 3)\t0.40301621080355077\n",
      "(2, 4)\t0.40301621080355077\n",
      "(2, 10)\t0.40301621080355077\n",
      "(2, 11)\t0.3065042162415877\n",
      "(2, 13)\t0.3065042162415877\n",
      "(2, 14)\t0.40301621080355077\n",
      "\n",
      "\n",
      "Feature Names:\n",
      "0: and\n",
      "1: coin\n",
      "2: collection\n",
      "3: do\n",
      "4: every\n",
      "5: for\n",
      "6: hobby\n",
      "7: is\n",
      "8: many\n",
      "9: my\n",
      "10: now\n",
      "11: painting\n",
      "12: passion\n",
      "13: some\n",
      "14: then\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Input text documents\n",
    "text_documents = [\n",
    "    'Painting is a hobby for many, passion for some',\n",
    "    'My hobby is coin collection',\n",
    "    'I do some Painting every now and then'\n",
    "]\n",
    "\n",
    "# Create the TF-IDF vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the documents to get the TF-IDF matrix\n",
    "tfidf_matrix = vectorizer.fit_transform(text_documents)\n",
    "\n",
    "# Get feature names (terms)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# Display the TF-IDF matrix\n",
    "print(\"TF-IDF Matrix:\")\n",
    "for i, doc_vector in enumerate(tfidf_matrix):\n",
    "    print(f\"Document {i}:\")\n",
    "    for j in range(doc_vector.shape[1]):\n",
    "        if doc_vector[0, j] != 0:\n",
    "            print(f\"({i}, {j})\\t{doc_vector[0, j]}\")\n",
    "    print()\n",
    "\n",
    "# Optional: Display feature names with their indices\n",
    "print(\"\\nFeature Names:\")\n",
    "for idx, term in enumerate(feature_names):\n",
    "    print(f\"{idx}: {term}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "33. How to create bigrams using Gensim’s Phraser ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Create bigrams from the given texts using Gensim library’s Phrases\n",
    "\n",
    "Input :\n",
    "\n",
    "documents = [\"the mayor of new york was there\", \"new york mayor was present\"]\n",
    "Desired Output:\n",
    "\n",
    " ['the', 'mayor', 'of', 'new york', 'was', 'there']\n",
    "['new york', 'mayor', 'was', 'present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'mayor', 'of', 'new_york', 'was', 'there']\n",
      "['new_york', 'mayor', 'was', 'present']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "\n",
    "# Input text documents\n",
    "documents = [\n",
    "    \"the mayor of new york was there\",\n",
    "    \"new york mayor was present\"\n",
    "]\n",
    "\n",
    "# Tokenize the text documents\n",
    "tokenized_docs = [simple_preprocess(doc) for doc in documents]\n",
    "\n",
    "# Train the Phrases model\n",
    "phrases = Phrases(tokenized_docs, min_count=1, threshold=1)\n",
    "\n",
    "# Create a Phraser from the Phrases model\n",
    "bigram_model = Phraser(phrases)\n",
    "\n",
    "# Transform the tokenized documents into bigrams\n",
    "bigram_docs = [bigram_model[doc] for doc in tokenized_docs]\n",
    "\n",
    "# Print the results\n",
    "for doc in bigram_docs:\n",
    "    print(doc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "35. How to detect the language of entered text ?  \n",
    ". Find out the language of the given textInput :\n",
    "\n",
    "\n",
    "text=\"El agente imprime su pase de abordaje. Los oficiales de seguridad del aeropuerto pasan junto a él con un perro grande. El perro está olfateando alrededor del equipaje de las personas tratando de detectar drogas o explosivos.\"\n",
    "\n",
    "Desired Output:\n",
    "\n",
    "{'language': 'es', 'score': 0.9999963653206719}\n",
    " El agente imprime su pase de abordaje. {'language': 'es', 'score': 0.9999969081229643} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 10.2/981.5 kB ? eta -:--:--\n",
      "     - ----------------------------------- 30.7/981.5 kB 262.6 kB/s eta 0:00:04\n",
      "     -- ---------------------------------- 71.7/981.5 kB 491.5 kB/s eta 0:00:02\n",
      "     ------ ----------------------------- 174.1/981.5 kB 876.1 kB/s eta 0:00:01\n",
      "     ------------ ------------------------- 317.4/981.5 kB 1.3 MB/s eta 0:00:01\n",
      "     -------------------- ----------------- 522.2/981.5 kB 1.8 MB/s eta 0:00:01\n",
      "     -------------------------------------  972.8/981.5 kB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 3.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: six in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from langdetect) (1.16.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993255 sha256=afca6ed583a4ecc06e3237a3ea9ee878cf82577f12bfe3ea76a8676404d66f13\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\d1\\c1\\d9\\7e068de779d863bc8f8fc9467d85e25cfe47fa5051fff1a1bb\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "!pip3 install langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'es', 'score': 0.9999954950287245}\n",
      "El agente imprime su pase de abordaje. {'language': 'es', 'score': 0.9999959883831963}\n",
      "Los oficiales de seguridad del aeropuerto pasan junto a él con un perro grande. {'language': 'es', 'score': 0.9999942941273458}\n",
      "El perro está olfateando alrededor del equipaje de las personas tratando de detectar drogas o explosivos.. {'language': 'es', 'score': 0.9999954100137014}\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect, detect_langs\n",
    "\n",
    "text = \"El agente imprime su pase de abordaje. Los oficiales de seguridad del aeropuerto pasan junto a él con un perro grande. El perro está olfateando alrededor del equipaje de las personas tratando de detectar drogas o explosivos.\"\n",
    "\n",
    "# Detecting language and score for the entire text\n",
    "languages = detect_langs(text)\n",
    "for lang in languages:\n",
    "    print({'language': lang.lang, 'score': lang.prob})\n",
    "\n",
    "# Detecting language and score for each sentence separately\n",
    "sentences = text.split('. ')\n",
    "for sentence in sentences:\n",
    "    if sentence.strip():  # Ensure the sentence is not empty\n",
    "        lang = detect_langs(sentence)[0]\n",
    "        print(f\"{sentence}. {{'language': '{lang.lang}', 'score': {lang.prob}}}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "36. How to merge two tokens as one ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Merge the first name and last name as single token in the given sentence\n",
    "\n",
    "Input:\n",
    "\n",
    "text=\"Robert Langdon is a famous character in various books and movies \"\n",
    "Desired Output:\n",
    "\n",
    "\n",
    "Robert Langdon\n",
    "is\n",
    "a\n",
    "famous\n",
    "character\n",
    "in\n",
    "various\n",
    "books\n",
    "and\n",
    "movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robert_Langdon\n",
      "is\n",
      "a\n",
      "famous\n",
      "character\n",
      "in\n",
      "various\n",
      "books\n",
      "and\n",
      "movies\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Robert Langdon is a famous character in various books and movies\"\n",
    "\n",
    "# Use a regular expression to find the first name followed by the last name\n",
    "merged_text = re.sub(r'Robert Langdon', 'Robert_Langdon', text)\n",
    "\n",
    "# Split the text into tokens\n",
    "tokens = merged_text.split()\n",
    "\n",
    "# Print each token on a new line\n",
    "for token in tokens:\n",
    "    print(token)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "37. How to extract Noun phrases from a text ?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Extract and print the noun phrases in given text document\n",
    "\n",
    "Input:\n",
    "\n",
    "text=\"There is a empty house on the Elm Street\"\n",
    "Expected Output :\n",
    "\n",
    "[a empty house, the Elm Street]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a empty house', 'the Elm Street']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the English language model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = \"There is a empty house on the Elm Street\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract and print noun phrases\n",
    "noun_phrases = [chunk.text for chunk in doc.noun_chunks]\n",
    "print(noun_phrases)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a empty house', 'the Elm Street']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"There is a empty house on the Elm Street\"\n",
    "\n",
    "# Regular expression pattern for noun phrases (e.g., 'a empty house', 'the Elm Street')\n",
    "# The pattern looks for:\n",
    "# (optional determiner/adjective) + (noun)\n",
    "pattern = r'\\b(?:the|a|an)?\\s*(?:\\w+\\s*)?(house|street)\\b'\n",
    "\n",
    "# Find all matches in the text\n",
    "matches = re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "# Post-process to construct full noun phrases\n",
    "noun_phrases = []\n",
    "for match in matches:\n",
    "    match_span = re.search(rf'\\b(?:the|a|an)?\\s*\\w*\\s*{match}\\b', text, re.IGNORECASE)\n",
    "    if match_span:\n",
    "        noun_phrases.append(match_span.group().strip())\n",
    "\n",
    "print(noun_phrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "38. How to extract Verb phrases from the text ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the Verb Phrases from the given text\n",
    "\n",
    "Input :\n",
    "\n",
    "text=(\"I may bake a cake for my birthday. The talk will introduce reader about Use of baking\")\n",
    "Desired Output:\n",
    "\n",
    " may bake\n",
    "will introduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['may bake', 'will introduce']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"I may bake a cake for my birthday. The talk will introduce reader about Use of baking\"\n",
    "\n",
    "# Regular expression pattern for verb phrases\n",
    "# The pattern looks for:\n",
    "# (modal/auxiliary verb) + (main verb)\n",
    "pattern = r'\\b(?:can|could|may|might|must|shall|should|will|would|is|are|was|were|be|being|been|has|have|had|do|does|did|am)\\s+\\w+\\b'\n",
    "\n",
    "# Find all matches in the text\n",
    "verb_phrases = re.findall(pattern, text, re.IGNORECASE)\n",
    "\n",
    "# Print the extracted verb phrases\n",
    "print(verb_phrases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "39. How to extract first name and last names present in the document ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract any two consecutive Proper Nouns that occour in the text document\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"Sherlock Holmes and Clint Thomas were good friends. I am a fan of John Mark\"\n",
    "Desired Output:\n",
    "\n",
    " Sherlock Holmes\n",
    " Clint Thomas\n",
    " John Mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sherlock Holmes\n",
      "Clint Thomas\n",
      "John Mark\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"Sherlock Holmes and Clint Thomas were good friends. I am a fan of John Mark\"\n",
    "\n",
    "# Regular expression pattern for two consecutive Proper Nouns\n",
    "# The pattern looks for two consecutive capitalized words\n",
    "pattern = r'\\b[A-Z][a-z]+\\s[A-Z][a-z]+\\b'\n",
    "\n",
    "# Find all matches in the text\n",
    "names = re.findall(pattern, text)\n",
    "\n",
    "# Print the extracted names\n",
    "for name in names:\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "40. How to identify named entities in the given text\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Identify and print all the named entities with their labels in the below text\n",
    "\n",
    "Input\n",
    "\n",
    "text=\" Walter works at Google. He lives in London.\"\n",
    "Desired Output:\n",
    "\n",
    " Walter PERSON\n",
    " Google ORG\n",
    " London GPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walter PERSON\n",
      "Google ORG\n",
      "London GPE\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = \"Walter works at Google. He lives in London.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract and print named entities with their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walter PERSON\n",
      "Google ORG\n",
      "He PERSON\n",
      "London GPE\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"Walter works at Google. He lives in London.\"\n",
    "\n",
    "# Basic patterns to match proper nouns, organizations, and locations\n",
    "# This is a simplified approach and may not catch all entities accurately\n",
    "\n",
    "# Pattern to identify capitalized words (assuming these are entities)\n",
    "pattern = r'\\b[A-Z][a-z]*\\b'\n",
    "\n",
    "# Find all capitalized words (simple heuristic for named entities)\n",
    "matches = re.findall(pattern, text)\n",
    "\n",
    "# Assuming the first capitalized word is a PERSON, the second is an ORG, and the third is a GPE\n",
    "entities = []\n",
    "for match in matches:\n",
    "    # You could use some logic to classify the entity, but for simplicity:\n",
    "    if match in [\"Google\"]:\n",
    "        entities.append((match, \"ORG\"))\n",
    "    elif match in [\"London\"]:\n",
    "        entities.append((match, \"GPE\"))\n",
    "    else:\n",
    "        entities.append((match, \"PERSON\"))\n",
    "\n",
    "# Print the named entities with their labels\n",
    "for entity in entities:\n",
    "    print(entity[0], entity[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "41. How to identify all the names of Organizations present in the text with NER ?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Identify and extract a list of all organizations/Companies mentioned in the given news article\n",
    "\n",
    "Input :\n",
    "\n",
    "text =\" Google has released it's new model which has got attention of everyone. Amazon is planning to expand into Food delivery, thereby giving competition . Apple is coming up with new iphone model. Flipkart will have to catch up soon.\"\n",
    "Expected Solution\n",
    "\n",
    " ['Google', 'Amazon', 'Apple', 'Flipkart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Google', 'Amazon', 'Apple', 'iPhone']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = (\"Google has released its new model which has got attention of everyone. \"\n",
    "        \"Amazon is planning to expand into Food delivery, thereby giving competition. \"\n",
    "        \"Apple is coming up with a new iPhone model. Flipkart will have to catch up soon.\")\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Extract organizations\n",
    "organizations = [ent.text for ent in doc.ents if ent.label_ == \"ORG\"]\n",
    "\n",
    "# Print the list of organizations\n",
    "print(organizations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "42. How to replace all names of people in the text with ‘UNKNOWN’\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Identify and replace all the person names in the news article with UNKNOWN to keep privacy\n",
    "Input :\n",
    "\n",
    "news=\" Walter was arrested yesterday at Brooklyn for murder. The suspicions and fingerprints pointed to Walter  and his friend  Pinkman . The arrest was made by inspector Hank\"\n",
    "Desired Output :\n",
    "\n",
    "'  UNKNOWN was arrested yesterday at Brooklyn for murder . The suspicions and fingerprints pointed to UNKNOWN   and his friend   UNKNOWN . The arrest was made by inspector UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNKNOWN was arrested yesterday at Brooklyn for murder. The suspicions and fingerprints pointed to UNKNOWN and his friend Pinkman. The arrest was made by inspector UNKNOWN.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input news text\n",
    "news = (\"Walter was arrested yesterday at Brooklyn for murder. The suspicions and \"\n",
    "        \"fingerprints pointed to Walter and his friend Pinkman. The arrest was made by inspector Hank.\")\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(news)\n",
    "\n",
    "# Replace names of people with 'UNKNOWN'\n",
    "updated_news = []\n",
    "last_end = 0\n",
    "\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PERSON\":\n",
    "        # Append text before the entity\n",
    "        updated_news.append(news[last_end:ent.start_char])\n",
    "        # Append 'UNKNOWN' in place of the person's name\n",
    "        updated_news.append('UNKNOWN')\n",
    "        last_end = ent.end_char\n",
    "\n",
    "# Append remaining text after the last entity\n",
    "updated_news.append(news[last_end:])\n",
    "\n",
    "# Join the parts to form the updated news text\n",
    "result = ''.join(updated_news)\n",
    "\n",
    "# Print the updated news text\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "43. How to visualize the named entities using spaCy\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Display the named entities prsent in the given document along with their categories using spacy\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\" Walter was arrested yesterday at Brooklyn for murder. The suspicions and fingerprints pointed to Walter  and his friend  Pinkman . He is from Paris \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " was arrested \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    yesterday\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " at \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brooklyn\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " for murder. The suspicions and fingerprints pointed to \n",
       "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Walter\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
       "</mark>\n",
       " and his friend Pinkman. He is from \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Paris\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = (\"Walter was arrested yesterday at Brooklyn for murder. The suspicions and fingerprints pointed to Walter and his friend Pinkman. He is from Paris.\")\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Visualize named entities using displacy\n",
    "displacy.render(doc, style='ent', jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "44. How to implement dependency parsing ?\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Find the dependencies of all the words in the given text\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"Mark plays volleyball every evening.\"\n",
    "Desired Output :\n",
    "\n",
    " Mark nsubj\n",
    " plays ROOT\n",
    " volleyball dobj\n",
    " every det\n",
    " evening npadvmod\n",
    " . punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark nsubj\n",
      "plays ROOT\n",
      "volleyball dobj\n",
      "every det\n",
      "evening npadvmod\n",
      ". punct\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = \"Mark plays volleyball every evening.\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print each token with its dependency label\n",
    "for token in doc:\n",
    "    print(f'{token.text} {token.dep_}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "45. How to find the ROOT word of any word in a sentence?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Find and print the root word / headword of any word in the given sentence\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"Mark plays volleyball. Sam is not into sports, he paints a lot\"\n",
    "Desired Output :\n",
    "\n",
    " Mark plays\n",
    " plays plays\n",
    " volleyball plays\n",
    " . plays\n",
    " Sam is\n",
    " is paints\n",
    " not is\n",
    " into is\n",
    " sports into\n",
    " , paints\n",
    " he paints\n",
    " paints paints\n",
    " a lot\n",
    " lot paints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mark plays\n",
      "plays plays\n",
      "volleyball plays\n",
      ". plays\n",
      "Sam is\n",
      "is paints\n",
      "not is\n",
      "into is\n",
      "sports into\n",
      ", paints\n",
      "he paints\n",
      "paints paints\n",
      "a lot\n",
      "lot paints\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = \"Mark plays volleyball. Sam is not into sports, he paints a lot\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print each token with its corresponding root (head word)\n",
    "for token in doc:\n",
    "    print(f'{token.text} {token.head.text}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "46. How to visualize the dependency tree in spaCy\n",
    "Difficulty Level : L2\n",
    "\n",
    "Q. Visualize the dependencies of various tokens of the given text using spaCy\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"Mark plays volleyball. Sam is not into sports, he paints a lot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"8f745e2a2a104c8482af530c8e6dd8b9-0\" class=\"displacy\" width=\"1490\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Mark</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"170\">plays</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"170\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">volleyball.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">Sam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">is</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">AUX</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">not</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">PART</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">into</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"890\">sports,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">he</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">PRON</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1130\">paints</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1130\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">a</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1370\">lot</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1370\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,122.0 160.0,122.0 160.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-1\" stroke-width=\"2px\" d=\"M190,182.0 C190,122.0 280.0,122.0 280.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M280.0,184.0 L288.0,172.0 272.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-2\" stroke-width=\"2px\" d=\"M430,182.0 C430,122.0 520.0,122.0 520.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M430,184.0 L422,172.0 438,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-3\" stroke-width=\"2px\" d=\"M550,182.0 C550,2.0 1130.0,2.0 1130.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M550,184.0 L542,172.0 558,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-4\" stroke-width=\"2px\" d=\"M550,182.0 C550,122.0 640.0,122.0 640.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M640.0,184.0 L648.0,172.0 632.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-5\" stroke-width=\"2px\" d=\"M550,182.0 C550,62.0 765.0,62.0 765.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M765.0,184.0 L773.0,172.0 757.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-6\" stroke-width=\"2px\" d=\"M790,182.0 C790,122.0 880.0,122.0 880.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M880.0,184.0 L888.0,172.0 872.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-7\" stroke-width=\"2px\" d=\"M1030,182.0 C1030,122.0 1120.0,122.0 1120.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1030,184.0 L1022,172.0 1038,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-8\" stroke-width=\"2px\" d=\"M1270,182.0 C1270,122.0 1360.0,122.0 1360.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1270,184.0 L1262,172.0 1278,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-9\" stroke-width=\"2px\" d=\"M1150,182.0 C1150,62.0 1365.0,62.0 1365.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-8f745e2a2a104c8482af530c8e6dd8b9-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1365.0,184.0 L1373.0,172.0 1357.0,172.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "\n",
    "# Load the spaCy English model\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Input text\n",
    "text = \"Mark plays volleyball. Sam is not into sports, he paints a lot\"\n",
    "\n",
    "# Process the text with spaCy\n",
    "doc = nlp(text)\n",
    "\n",
    "# Visualize the dependency tree\n",
    "displacy.render(doc, style='dep', jupyter=True, options={'distance': 120})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "47. How to detect all the Laptop names present in the text ?\n",
    "Difficulty Level : L4\n",
    "\n",
    "Q. Detect all the Laptop names present in the given  document .\n",
    "\n",
    "Input :\n",
    "\n",
    "text=\"For my offical use, I prefer lenova. For gaming purposes, I love asus\"\n",
    "Expected Output\n",
    "\n",
    "lenova laptop\n",
    "asus laptop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lenova laptop', 'asus laptop']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Input text\n",
    "text = \"For my official use, I prefer lenova. For gaming purposes, I love asus\"\n",
    "\n",
    "# List of known laptop brands\n",
    "laptop_brands = ['lenova', 'asus', 'dell', 'hp', 'apple', 'acer', 'microsoft', 'samsung', 'sony', 'toshiba', 'msi', 'razer']\n",
    "\n",
    "# Find and append \"laptop\" to each detected brand\n",
    "detected_laptops = []\n",
    "\n",
    "for brand in laptop_brands:\n",
    "    # Case-insensitive search for the brand in the text\n",
    "    matches = re.findall(r'\\b' + re.escape(brand) + r'\\b', text, re.IGNORECASE)\n",
    "    for match in matches:\n",
    "        detected_laptops.append(f\"{match.lower()} laptop\")\n",
    "\n",
    "# Print the detected laptop names\n",
    "print(detected_laptops)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "48. How to summarize text using gensim ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the summary of the given text based using gensim package based on the TextRank Algorithm.\n",
    "\n",
    "Input :\n",
    "\n",
    "original_text=\"\"\"Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, improve your sex life, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma. \n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\"\"\"\n",
    "Desired Output :\n",
    "\n",
    " As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%.\n",
    " No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    " The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    " As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (4.3.3)\n",
      "Requirement already satisfied: numpy<2.0,>=1.18.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from gensim) (1.13.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from gensim) (7.0.4)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "# Input text\n",
    "original_text = \"\"\"\n",
    "Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, improve your sex life, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma. \n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\n",
    "\"\"\"\n",
    "\n",
    "# Generate summary\n",
    "summary = summarize(original_text, ratio=0.1)\n",
    "\n",
    "# Print the summary\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "49. How to summarize text based on the LexRank algorithm ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the summary of the given text based on the TextRank Algorithm.\n",
    "\n",
    "Input :\n",
    "\n",
    "original_text=\"\"\"Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, improve your sex life, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma. \n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\"\"\"\n",
    "Desired Output :\n",
    "\n",
    " Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma.>, <Sentence: Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\DELL\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma. Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "\n",
    "def lexrank_summary(text, num_sentences=2):\n",
    "    sentences = sent_tokenize(text)\n",
    "    tfidf_vectorizer = TfidfVectorizer().fit_transform(sentences)\n",
    "    similarity_matrix = cosine_similarity(tfidf_vectorizer, tfidf_vectorizer)\n",
    "    \n",
    "    # Create a graph where nodes are sentences and edges are similarities\n",
    "    similarity_graph = np.array(similarity_matrix)\n",
    "    \n",
    "    # Apply PageRank algorithm\n",
    "    scores = np.sum(similarity_graph, axis=1)\n",
    "    ranked_sentences = [sentences[i] for i in np.argsort(scores, axis=0)[::-1]]\n",
    "    \n",
    "    return ' '.join(ranked_sentences[:num_sentences])\n",
    "\n",
    "original_text = \"\"\"\n",
    "Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, improve your sex life, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma.\n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\n",
    "\"\"\"\n",
    "\n",
    "summary = lexrank_summary(original_text, num_sentences=2)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "50. How to summarize text using Luhn algorithm?\n",
    "Q. Extract the summary of the given text based on the Luhn Algorithm.\n",
    "\n",
    "Difficulty Level : L3\n",
    "\n",
    "Input :\n",
    "\n",
    "original_text=\"\"\"Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma. \n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\"\"\"\n",
    "Desired Output :\n",
    "\n",
    "  Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.  Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sumy\n",
      "  Downloading sumy-0.11.0-py2.py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting docopt<0.7,>=0.6.1 (from sumy)\n",
      "  Using cached docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting breadability>=0.1.20 (from sumy)\n",
      "  Downloading breadability-0.1.20.tar.gz (32 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: requests>=2.7.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from sumy) (2.32.2)\n",
      "Requirement already satisfied: pycountry>=18.2.23 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from sumy) (24.6.1)\n",
      "Requirement already satisfied: nltk>=3.0.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from sumy) (3.8.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from breadability>=0.1.20->sumy) (4.0.0)\n",
      "Collecting lxml>=2.0 (from breadability>=0.1.20->sumy)\n",
      "  Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: click in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from nltk>=3.0.2->sumy) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from nltk>=3.0.2->sumy) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from nltk>=3.0.2->sumy) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from nltk>=3.0.2->sumy) (4.66.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests>=2.7.0->sumy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests>=2.7.0->sumy) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests>=2.7.0->sumy) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests>=2.7.0->sumy) (2023.7.22)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from click->nltk>=3.0.2->sumy) (0.4.6)\n",
      "Downloading sumy-0.11.0-py2.py3-none-any.whl (97 kB)\n",
      "   ---------------------------------------- 0.0/97.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/97.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 97.3/97.3 kB 5.4 MB/s eta 0:00:00\n",
      "Downloading lxml-5.3.0-cp39-cp39-win_amd64.whl (3.8 MB)\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/3.8 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.1/3.8 MB 1.1 MB/s eta 0:00:04\n",
      "   - -------------------------------------- 0.1/3.8 MB 1.3 MB/s eta 0:00:03\n",
      "   - -------------------------------------- 0.1/3.8 MB 1.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.2/3.8 MB 1.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.2/3.8 MB 1.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.2/3.8 MB 1.1 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.3/3.8 MB 948.8 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.3/3.8 MB 884.2 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.4/3.8 MB 857.5 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 836.4 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.4/3.8 MB 819.2 kB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 0.5/3.8 MB 823.7 kB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 832.7 kB/s eta 0:00:04\n",
      "   ----- ---------------------------------- 0.5/3.8 MB 830.7 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.6/3.8 MB 818.6 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.6/3.8 MB 818.6 kB/s eta 0:00:04\n",
      "   ------ --------------------------------- 0.6/3.8 MB 783.7 kB/s eta 0:00:05\n",
      "   ------ --------------------------------- 0.7/3.8 MB 779.1 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.7/3.8 MB 772.4 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.7/3.8 MB 768.6 kB/s eta 0:00:05\n",
      "   ------- -------------------------------- 0.7/3.8 MB 762.9 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 745.8 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 754.8 kB/s eta 0:00:04\n",
      "   -------- ------------------------------- 0.8/3.8 MB 739.5 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.8/3.8 MB 728.2 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.9/3.8 MB 724.0 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.9/3.8 MB 723.5 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.9/3.8 MB 723.5 kB/s eta 0:00:05\n",
      "   --------- ------------------------------ 0.9/3.8 MB 710.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 701.0 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 691.9 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 676.6 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 676.2 kB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 1.0/3.8 MB 675.5 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 661.7 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 655.4 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 661.4 kB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 1.1/3.8 MB 655.4 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 1.2/3.8 MB 649.4 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 1.2/3.8 MB 649.6 kB/s eta 0:00:05\n",
      "   ------------ --------------------------- 1.2/3.8 MB 649.7 kB/s eta 0:00:04\n",
      "   ------------ --------------------------- 1.2/3.8 MB 649.9 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.3/3.8 MB 644.6 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.3/3.8 MB 640.0 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 1.3/3.8 MB 640.3 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.3/3.8 MB 640.6 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.4/3.8 MB 640.9 kB/s eta 0:00:04\n",
      "   -------------- ------------------------- 1.4/3.8 MB 641.2 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.4/3.8 MB 641.4 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.5/3.8 MB 637.2 kB/s eta 0:00:04\n",
      "   --------------- ------------------------ 1.5/3.8 MB 646.4 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.5/3.8 MB 646.8 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 646.7 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 646.7 kB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 1.6/3.8 MB 639.0 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 639.2 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.6/3.8 MB 631.6 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 632.0 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.7/3.8 MB 628.6 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.7/3.8 MB 632.7 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.8/3.8 MB 629.4 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.8/3.8 MB 629.8 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.8/3.8 MB 630.1 kB/s eta 0:00:04\n",
      "   ------------------ --------------------- 1.8/3.8 MB 630.1 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 1.8/3.8 MB 623.9 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 1.9/3.8 MB 617.8 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 1.9/3.8 MB 618.3 kB/s eta 0:00:04\n",
      "   ------------------- -------------------- 1.9/3.8 MB 612.1 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.9/3.8 MB 615.6 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.9/3.8 MB 615.6 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 1.9/3.8 MB 604.2 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.0/3.8 MB 601.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.0/3.8 MB 601.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.0/3.8 MB 590.8 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 2.0/3.8 MB 585.8 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.0/3.8 MB 580.8 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.0/3.8 MB 579.0 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.0/3.8 MB 579.6 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.1/3.8 MB 572.4 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.1/3.8 MB 573.1 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 2.1/3.8 MB 568.6 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 569.2 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 567.7 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 2.1/3.8 MB 560.9 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 2.2/3.8 MB 561.8 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 2.2/3.8 MB 559.9 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 561.3 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 559.5 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.2/3.8 MB 559.5 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.3/3.8 MB 554.1 kB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 2.3/3.8 MB 552.8 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 2.3/3.8 MB 553.6 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 2.3/3.8 MB 549.8 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 2.3/3.8 MB 546.6 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 2.3/3.8 MB 544.9 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 2.4/3.8 MB 545.7 kB/s eta 0:00:03\n",
      "   ------------------------ --------------- 2.4/3.8 MB 544.5 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 2.4/3.8 MB 543.0 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 2.4/3.8 MB 540.4 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 2.4/3.8 MB 539.3 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 2.5/3.8 MB 540.1 kB/s eta 0:00:03\n",
      "   ------------------------- -------------- 2.5/3.8 MB 536.8 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.5/3.8 MB 535.8 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.5/3.8 MB 534.4 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.5/3.8 MB 535.2 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.5/3.8 MB 536.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 2.5/3.8 MB 532.8 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 2.6/3.8 MB 532.4 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 2.6/3.8 MB 533.2 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 2.6/3.8 MB 533.9 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 2.6/3.8 MB 532.6 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 2.7/3.8 MB 532.1 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 532.8 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 535.3 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 534.7 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 2.7/3.8 MB 533.5 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 534.9 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 533.7 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 534.8 kB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 2.8/3.8 MB 537.1 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.9/3.8 MB 538.1 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.9/3.8 MB 537.5 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 2.9/3.8 MB 539.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.0/3.8 MB 540.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.0/3.8 MB 541.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 3.0/3.8 MB 542.5 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.1/3.8 MB 545.5 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.1/3.8 MB 544.3 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.1/3.8 MB 544.3 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 3.1/3.8 MB 544.3 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.1/3.8 MB 546.5 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.2/3.8 MB 543.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.2/3.8 MB 544.9 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.2/3.8 MB 543.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 3.2/3.8 MB 542.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 3.2/3.8 MB 544.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 3.3/3.8 MB 544.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.3/3.8 MB 544.7 kB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 3.3/3.8 MB 544.2 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.3/3.8 MB 546.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.3/3.8 MB 545.0 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 545.8 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 3.4/3.8 MB 547.0 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.4/3.8 MB 545.8 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 546.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 547.2 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.5/3.8 MB 548.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.5/3.8 MB 548.5 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 549.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 550.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 3.6/3.8 MB 551.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.6/3.8 MB 552.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 553.3 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 553.8 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 3.7/3.8 MB 553.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  3.7/3.8 MB 553.7 kB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 551.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 550.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  3.8/3.8 MB 550.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.8/3.8 MB 550.8 kB/s eta 0:00:00\n",
      "Building wheels for collected packages: breadability, docopt\n",
      "  Building wheel for breadability (setup.py): started\n",
      "  Building wheel for breadability (setup.py): finished with status 'done'\n",
      "  Created wheel for breadability: filename=breadability-0.1.20-py2.py3-none-any.whl size=21739 sha256=f5a59399a895b38f5d449f45b0a553d865a8600a0bf5b343120c670ef3d1407d\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\ba\\9f\\70\\7795228568b81b57a8932755938da9fb1f291b0576752604aa\n",
      "  Building wheel for docopt (setup.py): started\n",
      "  Building wheel for docopt (setup.py): finished with status 'done'\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13773 sha256=af1e6a090c70b58e70e42e7cd47edf95fce4879b35269bce2168dfa50608ad87\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\70\\4a\\46\\1309fc853b8d395e60bafaf1b6df7845bdd82c95fd59dd8d2b\n",
      "Successfully built breadability docopt\n",
      "Installing collected packages: docopt, lxml, breadability, sumy\n",
      "Successfully installed breadability-0.1.20 docopt-0.6.2 lxml-5.3.0 sumy-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sumy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
      "Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma.\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.luhn import LuhnSummarizer\n",
    "\n",
    "# Your input text\n",
    "original_text = \"\"\"\n",
    "Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma.\n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\n",
    "\"\"\"\n",
    "\n",
    "# Parsing the text\n",
    "parser = PlaintextParser.from_string(original_text, Tokenizer(\"english\"))\n",
    "\n",
    "# Summarizing the text using Luhn algorithm\n",
    "summarizer = LuhnSummarizer()\n",
    "summary = summarizer(parser.document, 2)\n",
    "\n",
    "# Printing the summary\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51. How to summarize text based on LSA algorithm ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Extract the summary of the given text based on the LSA Algorithm.\n",
    "\n",
    "Input :\n",
    "\n",
    "original_text=\"\"\"Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind.Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma. \n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\"\"\"\n",
    "Desired Output :\n",
    "\n",
    "In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing. People who exercise regularly tend to do so because it gives them an enormous sense of well-being."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
      "People who exercise regularly tend to do so because it gives them an enormous sense of well-being.\n"
     ]
    }
   ],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.lsa import LsaSummarizer\n",
    "\n",
    "# Sample input text\n",
    "original_text = \"\"\"\n",
    "Studies show that exercise can treat mild to moderate depression as effectively as antidepressant medication—but without the side-effects, of course. As one example, a recent study done by the Harvard T.H. Chan School of Public Health found that running for 15 minutes a day or walking for an hour reduces the risk of major depression by 26%. In addition to relieving depression symptoms, research also shows that maintaining an exercise schedule can prevent you from relapsing.\n",
    "Exercise is a powerful depression fighter for several reasons. Most importantly, it promotes all kinds of changes in the brain, including neural growth, reduced inflammation, and new activity patterns that promote feelings of calm and well-being. It also releases endorphins, powerful chemicals in your brain that energize your spirits and make you feel good. Finally, exercise can also serve as a distraction, allowing you to find some quiet time to break out of the cycle of negative thoughts that feed depression.\n",
    "Exercise is not just about aerobic capacity and muscle size. Sure, exercise can improve your physical health and your physique, trim your waistline, and even add years to your life. But that’s not what motivates most people to stay active.\n",
    "People who exercise regularly tend to do so because it gives them an enormous sense of well-being. They feel more energetic throughout the day, sleep better at night, have sharper memories, and feel more relaxed and positive about themselves and their lives. And it’s also powerful medicine for many common mental health challenges.\n",
    "Regular exercise can have a profoundly positive impact on depression, anxiety, ADHD, and more. It also relieves stress, improves memory, helps you sleep better, and boosts your overall mood. And you don’t have to be a fitness fanatic to reap the benefits. Research indicates that modest amounts of exercise can make a difference. No matter your age or fitness level, you can learn to use exercise as a powerful tool to feel better.\n",
    "Ever noticed how your body feels when you’re under stress? Your muscles may be tense, especially in your face, neck, and shoulders, leaving you with back or neck pain, or painful headaches. You may feel a tightness in your chest, a pounding pulse, or muscle cramps. You may also experience problems such as insomnia, heartburn, stomachache, diarrhea, or frequent urination. The worry and discomfort of all these physical symptoms can in turn lead to even more stress, creating a vicious cycle between your mind and body.\n",
    "Exercising is an effective way to break this cycle. As well as releasing endorphins in the brain, physical activity helps to relax the muscles and relieve tension in the body. Since the body and mind are so closely linked, when your body feels better so, too, will your mind. Evidence suggests that by really focusing on your body and how it feels as you exercise, you can actually help your nervous system become “unstuck” and begin to move out of the immobilization stress response that characterizes PTSD or trauma.\n",
    "Instead of allowing your mind to wander, pay close attention to the physical sensations in your joints and muscles, even your insides as your body moves. Exercises that involve cross movement and that engage both arms and legs—such as walking (especially in sand), running, swimming, weight training, or dancing—are some of your best choices.\n",
    "Outdoor activities like hiking, sailing, mountain biking, rock climbing, whitewater rafting, and skiing (downhill and cross-country) have also been shown to reduce the symptoms of PTSD.\n",
    "\"\"\"\n",
    "\n",
    "# Create a parser for the input text\n",
    "parser = PlaintextParser.from_string(original_text, Tokenizer(\"english\"))\n",
    "\n",
    "# Create an LSA summarizer\n",
    "summarizer = LsaSummarizer()\n",
    "\n",
    "# Summarize the text and select the top 2 sentences\n",
    "summary = summarizer(parser.document, 2)\n",
    "\n",
    "# Print the summary\n",
    "for sentence in summary:\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "52. How to convert documents into json format ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Covert the given text documents into json format for spacy usage\n",
    "\n",
    "Input:\n",
    "\n",
    "text1=\"Netflix has released a new series\"\n",
    "text2=\"It was shot in London\"\n",
    "text3=\"It is called Dark and the main character is Jonas\"\n",
    "text4=\"Adam is the evil character\"\n",
    "Desired Output :\n",
    "\n",
    "{'id': 0,\n",
    " 'paragraphs': [{'cats': [],\n",
    "   'raw': 'Netflix has released a new series',\n",
    "   'sentences': [{'brackets': [],\n",
    "     'tokens': [{'dep': 'nsubj',\n",
    "       'head': 2,\n",
    "       'id': 0,\n",
    "       'ner': 'U-ORG',\n",
    "       'orth': 'Netflix',\n",
    "       'tag': 'NNP'},\n",
    "      {'dep': 'aux',\n",
    "       'head': 1,\n",
    "       'id': 1,\n",
    "       'ner': 'O',\n",
    "       'orth': 'has',\n",
    "       'tag': 'VBZ'},\n",
    "      {'dep': 'ROOT',\n",
    "       'head': 0,\n",
    "       'id': 2,\n",
    "       'ner': 'O',\n",
    "       'orth': 'released',\n",
    "       'tag': 'VBN'},\n",
    "      {'dep': 'det', 'head': 2, 'id': 3, 'ner': 'O', 'orth': 'a', 'tag': 'DT'},\n",
    "      {'dep': 'amod',\n",
    "       'head': 1,\n",
    "       'id': 4,\n",
    "       'ner': 'O',\n",
    "       'orth': 'new',\n",
    "       'tag': 'JJ'},\n",
    "      {'dep': 'dobj',\n",
    "       'head': -3,\n",
    "       'id': 5,\n",
    "       'ner': 'O',\n",
    "       'orth': 'series',\n",
    "       'tag': 'NN'}]}]},\n",
    "    ...(truncated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"id\": 0,\n",
      "    \"paragraphs\": [\n",
      "      {\n",
      "        \"raw\": \"Netflix has released a new series\",\n",
      "        \"cats\": [],\n",
      "        \"sentences\": [\n",
      "          {\n",
      "            \"tokens\": [\n",
      "              {\n",
      "                \"id\": 0,\n",
      "                \"orth\": \"Netflix\",\n",
      "                \"tag\": \"NNP\",\n",
      "                \"dep\": \"nsubj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"U-ORG\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 1,\n",
      "                \"orth\": \"has\",\n",
      "                \"tag\": \"VBZ\",\n",
      "                \"dep\": \"aux\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 2,\n",
      "                \"orth\": \"released\",\n",
      "                \"tag\": \"VBN\",\n",
      "                \"dep\": \"ROOT\",\n",
      "                \"head\": 0,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 3,\n",
      "                \"orth\": \"a\",\n",
      "                \"tag\": \"DT\",\n",
      "                \"dep\": \"det\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 4,\n",
      "                \"orth\": \"new\",\n",
      "                \"tag\": \"JJ\",\n",
      "                \"dep\": \"amod\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 5,\n",
      "                \"orth\": \"series\",\n",
      "                \"tag\": \"NN\",\n",
      "                \"dep\": \"dobj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 1,\n",
      "    \"paragraphs\": [\n",
      "      {\n",
      "        \"raw\": \"It was shot in London\",\n",
      "        \"cats\": [],\n",
      "        \"sentences\": [\n",
      "          {\n",
      "            \"tokens\": [\n",
      "              {\n",
      "                \"id\": 0,\n",
      "                \"orth\": \"Netflix\",\n",
      "                \"tag\": \"NNP\",\n",
      "                \"dep\": \"nsubj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"U-ORG\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 1,\n",
      "                \"orth\": \"has\",\n",
      "                \"tag\": \"VBZ\",\n",
      "                \"dep\": \"aux\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 2,\n",
      "                \"orth\": \"released\",\n",
      "                \"tag\": \"VBN\",\n",
      "                \"dep\": \"ROOT\",\n",
      "                \"head\": 0,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 3,\n",
      "                \"orth\": \"a\",\n",
      "                \"tag\": \"DT\",\n",
      "                \"dep\": \"det\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 4,\n",
      "                \"orth\": \"new\",\n",
      "                \"tag\": \"JJ\",\n",
      "                \"dep\": \"amod\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 5,\n",
      "                \"orth\": \"series\",\n",
      "                \"tag\": \"NN\",\n",
      "                \"dep\": \"dobj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 2,\n",
      "    \"paragraphs\": [\n",
      "      {\n",
      "        \"raw\": \"It is called Dark and the main character is Jonas\",\n",
      "        \"cats\": [],\n",
      "        \"sentences\": [\n",
      "          {\n",
      "            \"tokens\": [\n",
      "              {\n",
      "                \"id\": 0,\n",
      "                \"orth\": \"Netflix\",\n",
      "                \"tag\": \"NNP\",\n",
      "                \"dep\": \"nsubj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"U-ORG\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 1,\n",
      "                \"orth\": \"has\",\n",
      "                \"tag\": \"VBZ\",\n",
      "                \"dep\": \"aux\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 2,\n",
      "                \"orth\": \"released\",\n",
      "                \"tag\": \"VBN\",\n",
      "                \"dep\": \"ROOT\",\n",
      "                \"head\": 0,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 3,\n",
      "                \"orth\": \"a\",\n",
      "                \"tag\": \"DT\",\n",
      "                \"dep\": \"det\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 4,\n",
      "                \"orth\": \"new\",\n",
      "                \"tag\": \"JJ\",\n",
      "                \"dep\": \"amod\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 5,\n",
      "                \"orth\": \"series\",\n",
      "                \"tag\": \"NN\",\n",
      "                \"dep\": \"dobj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": 3,\n",
      "    \"paragraphs\": [\n",
      "      {\n",
      "        \"raw\": \"Adam is the evil character\",\n",
      "        \"cats\": [],\n",
      "        \"sentences\": [\n",
      "          {\n",
      "            \"tokens\": [\n",
      "              {\n",
      "                \"id\": 0,\n",
      "                \"orth\": \"Netflix\",\n",
      "                \"tag\": \"NNP\",\n",
      "                \"dep\": \"nsubj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"U-ORG\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 1,\n",
      "                \"orth\": \"has\",\n",
      "                \"tag\": \"VBZ\",\n",
      "                \"dep\": \"aux\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 2,\n",
      "                \"orth\": \"released\",\n",
      "                \"tag\": \"VBN\",\n",
      "                \"dep\": \"ROOT\",\n",
      "                \"head\": 0,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 3,\n",
      "                \"orth\": \"a\",\n",
      "                \"tag\": \"DT\",\n",
      "                \"dep\": \"det\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 4,\n",
      "                \"orth\": \"new\",\n",
      "                \"tag\": \"JJ\",\n",
      "                \"dep\": \"amod\",\n",
      "                \"head\": 5,\n",
      "                \"ner\": \"O\"\n",
      "              },\n",
      "              {\n",
      "                \"id\": 5,\n",
      "                \"orth\": \"series\",\n",
      "                \"tag\": \"NN\",\n",
      "                \"dep\": \"dobj\",\n",
      "                \"head\": 2,\n",
      "                \"ner\": \"O\"\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Sample text documents\n",
    "text1 = \"Netflix has released a new series\"\n",
    "text2 = \"It was shot in London\"\n",
    "text3 = \"It is called Dark and the main character is Jonas\"\n",
    "text4 = \"Adam is the evil character\"\n",
    "\n",
    "# Dummy annotation functions (you need to replace these with actual annotations from spaCy or other NLP tools)\n",
    "def dummy_annotations(text):\n",
    "    # This function should return detailed annotations for each token in the text\n",
    "    # Here we provide a dummy example\n",
    "    return {\n",
    "        'tokens': [\n",
    "            {'id': 0, 'orth': 'Netflix', 'tag': 'NNP', 'dep': 'nsubj', 'head': 2, 'ner': 'U-ORG'},\n",
    "            {'id': 1, 'orth': 'has', 'tag': 'VBZ', 'dep': 'aux', 'head': 2, 'ner': 'O'},\n",
    "            {'id': 2, 'orth': 'released', 'tag': 'VBN', 'dep': 'ROOT', 'head': 0, 'ner': 'O'},\n",
    "            {'id': 3, 'orth': 'a', 'tag': 'DT', 'dep': 'det', 'head': 5, 'ner': 'O'},\n",
    "            {'id': 4, 'orth': 'new', 'tag': 'JJ', 'dep': 'amod', 'head': 5, 'ner': 'O'},\n",
    "            {'id': 5, 'orth': 'series', 'tag': 'NN', 'dep': 'dobj', 'head': 2, 'ner': 'O'}\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def create_json(text, id):\n",
    "    return {\n",
    "        'id': id,\n",
    "        'paragraphs': [\n",
    "            {\n",
    "                'raw': text,\n",
    "                'cats': [],\n",
    "                'sentences': [\n",
    "                    {\n",
    "                        'tokens': dummy_annotations(text)['tokens']\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "# Convert texts to JSON format\n",
    "documents = [\n",
    "    create_json(text1, 0),\n",
    "    create_json(text2, 1),\n",
    "    create_json(text3, 2),\n",
    "    create_json(text4, 3)\n",
    "]\n",
    "\n",
    "# Output JSON\n",
    "output_json = json.dumps(documents, indent=2)\n",
    "print(output_json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53. How to build a text classifier with TextBlob ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q Build a text classifier with available train data using textblob library\n",
    "\n",
    "Input:\n",
    "\n",
    "# Data to train the classifier\n",
    "train = [\n",
    "    ('I love eating sushi','food-review'),\n",
    "    ('This is an amazing place!', 'Tourist-review'),\n",
    "    ('Pizza is my all time favorite food','food-review'),\n",
    "    ('I baked a cake yesterday, it was tasty', 'food-review'),\n",
    "    (\"What an awesome taste this sushi has\", 'food-review'),\n",
    "    ('It is a perfect place for outing', 'Tourist-review'),\n",
    "    ('This is a nice picnic spot', 'Tourist-review'),\n",
    "    (\"Families come out on tours here\", 'Tourist-review'),\n",
    "    ('It is a beautiful place !', 'Tourist-review'),\n",
    "    ('The place was warm and nice', 'Tourist-review')\n",
    "]\n",
    "test = [\n",
    "    ('The sushi was good', 'food-review'),\n",
    "    ('The place was perfect for picnics ', 'Tourist-review'),\n",
    "    (\"Burgers are my favorite food\", 'food-review'),\n",
    "    (\"I feel amazing!\", 'food-review'),\n",
    "    ('It is an amazing place', 'Tourist-review'),\n",
    "    (\"This isn't a very good place\", 'Tourist-review')\n",
    "]\n",
    "Desired Output :\n",
    "\n",
    " Accuracy: 0.8333333333333334"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "from textblob import Blobber\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "\n",
    "# Define the train and test data\n",
    "train = [\n",
    "    ('I love eating sushi', 'food-review'),\n",
    "    ('This is an amazing place!', 'Tourist-review'),\n",
    "    ('Pizza is my all time favorite food', 'food-review'),\n",
    "    ('I baked a cake yesterday, it was tasty', 'food-review'),\n",
    "    (\"What an awesome taste this sushi has\", 'food-review'),\n",
    "    ('It is a perfect place for outing', 'Tourist-review'),\n",
    "    ('This is a nice picnic spot', 'Tourist-review'),\n",
    "    (\"Families come out on tours here\", 'Tourist-review'),\n",
    "    ('It is a beautiful place !', 'Tourist-review'),\n",
    "    ('The place was warm and nice', 'Tourist-review')\n",
    "]\n",
    "\n",
    "test = [\n",
    "    ('The sushi was good', 'food-review'),\n",
    "    ('The place was perfect for picnics ', 'Tourist-review'),\n",
    "    (\"Burgers are my favorite food\", 'food-review'),\n",
    "    (\"I feel amazing!\", 'food-review'),\n",
    "    ('It is an amazing place', 'Tourist-review'),\n",
    "    (\"This isn't a very good place\", 'Tourist-review')\n",
    "]\n",
    "\n",
    "# Create and train the classifier\n",
    "classifier = NaiveBayesClassifier(train)\n",
    "\n",
    "# Evaluate on the test set\n",
    "test_texts = [text for text, label in test]\n",
    "true_labels = [label for text, label in test]\n",
    "\n",
    "predicted_labels = [classifier.classify(text) for text in test_texts]\n",
    "\n",
    "# Calculate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "54. How to train a text classifier using Simple transformers ?\n",
    "Difficulty Level : L4\n",
    "\n",
    "Q. Build and train a text classifier for the given data using simpletransformers library\n",
    "\n",
    "Input :\n",
    "\n",
    "train_data = [\n",
    "    [\"The movie was amazing\", 1],\n",
    "    [\"It was a boring movie\", 0],\n",
    "    [\"I had a great experience\",1],\n",
    "    [\"I was bored during the movie\",0],\n",
    "    [\"The movie was great\",1],\n",
    "    [\"The movie was bad\",0],\n",
    "    [\"The movie was good\",1]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
      "     ---------------------------------------- 0.0/42.4 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/42.4 kB 330.3 kB/s eta 0:00:01\n",
      "     ------------------------------------ - 41.0/42.4 kB 393.8 kB/s eta 0:00:01\n",
      "     -------------------------------------- 42.4/42.4 kB 412.4 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (1.23.5)\n",
      "Requirement already satisfied: requests in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (2.32.2)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (4.66.4)\n",
      "Requirement already satisfied: regex in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (2024.5.15)\n",
      "Requirement already satisfied: transformers>=4.31.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (4.42.3)\n",
      "Collecting datasets (from simpletransformers)\n",
      "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
      "Requirement already satisfied: scipy in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (1.5.1)\n",
      "Collecting seqeval (from simpletransformers)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     ---------------------------------------- 0.0/43.6 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.6/43.6 kB 2.2 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: tensorboard in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (2.12.3)\n",
      "Collecting tensorboardx (from simpletransformers)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (2.2.2)\n",
      "Requirement already satisfied: tokenizers in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (0.19.1)\n",
      "Collecting wandb>=0.10.32 (from simpletransformers)\n",
      "  Downloading wandb-0.17.7-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: streamlit in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from simpletransformers) (1.35.0)\n",
      "Collecting sentencepiece (from simpletransformers)\n",
      "  Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tqdm>=4.47.0->simpletransformers) (0.4.6)\n",
      "Requirement already satisfied: filelock in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.23.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (6.0.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from transformers>=4.31.0->simpletransformers) (0.4.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (8.1.7)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (4.2.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<6,>=3.19.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (4.25.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (5.9.8)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting setproctitle (from wandb>=0.10.32->simpletransformers)\n",
      "  Downloading setproctitle-1.3.3-cp39-cp39-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (69.5.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from wandb>=0.10.32->simpletransformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests->simpletransformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests->simpletransformers) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests->simpletransformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests->simpletransformers) (2023.7.22)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from datasets->simpletransformers) (16.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->simpletransformers)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->simpletransformers)\n",
      "  Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from datasets->simpletransformers)\n",
      "  Downloading multiprocess-0.70.16-py39-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets->simpletransformers) (2024.6.0)\n",
      "Collecting aiohttp (from datasets->simpletransformers)\n",
      "  Downloading aiohttp-3.10.5-cp39-cp39-win_amd64.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pandas->simpletransformers) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pandas->simpletransformers) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pandas->simpletransformers) (2024.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (5.3.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (1.8.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (5.3.3)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (10.3.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (13.7.1)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (8.3.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (0.9.1)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (6.4.1)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from streamlit->simpletransformers) (4.0.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (1.64.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (2.30.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (3.0.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tensorboard->simpletransformers) (0.43.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.22.0)\n",
      "Requirement already satisfied: toolz in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.1)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb>=0.10.32->simpletransformers) (1.16.0)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets->simpletransformers)\n",
      "  Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets->simpletransformers)\n",
      "  Using cached aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from aiohttp->datasets->simpletransformers) (23.2.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets->simpletransformers)\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets->simpletransformers)\n",
      "  Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl.metadata (4.3 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets->simpletransformers)\n",
      "  Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl.metadata (32 kB)\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets->simpletransformers)\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (2.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from markdown>=2.6.8->tensorboard->simpletransformers) (7.1.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->simpletransformers) (3.19.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.18.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.6.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->simpletransformers) (3.2.2)\n",
      "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
      "   ---------------------------------------- 0.0/316.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.3 kB ? eta -:--:--\n",
      "   - -------------------------------------- 10.2/316.3 kB ? eta -:--:--\n",
      "   -------- ------------------------------ 71.7/316.3 kB 357.2 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/316.3 kB 374.1 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 112.6/316.3 kB 409.6 kB/s eta 0:00:01\n",
      "   -------------- ----------------------- 122.9/316.3 kB 379.3 kB/s eta 0:00:01\n",
      "   ----------------- -------------------- 143.4/316.3 kB 369.8 kB/s eta 0:00:01\n",
      "   ------------------ ------------------- 153.6/316.3 kB 366.6 kB/s eta 0:00:01\n",
      "   -------------------- ----------------- 174.1/316.3 kB 388.2 kB/s eta 0:00:01\n",
      "   ----------------------- -------------- 194.6/316.3 kB 393.0 kB/s eta 0:00:01\n",
      "   ------------------------ ------------- 204.8/316.3 kB 377.1 kB/s eta 0:00:01\n",
      "   --------------------------- ---------- 225.3/316.3 kB 393.1 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 256.0/316.3 kB 393.2 kB/s eta 0:00:01\n",
      "   --------------------------------- ---- 276.5/316.3 kB 405.2 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 286.7/316.3 kB 401.9 kB/s eta 0:00:01\n",
      "   ------------------------------------ - 307.2/316.3 kB 387.7 kB/s eta 0:00:01\n",
      "   -------------------------------------- 316.3/316.3 kB 391.4 kB/s eta 0:00:00\n",
      "Downloading wandb-0.17.7-py3-none-win_amd64.whl (6.5 MB)\n",
      "   ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/6.5 MB 487.6 kB/s eta 0:00:14\n",
      "   ---------------------------------------- 0.1/6.5 MB 544.7 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.1/6.5 MB 521.8 kB/s eta 0:00:13\n",
      "    --------------------------------------- 0.1/6.5 MB 490.2 kB/s eta 0:00:14\n",
      "    --------------------------------------- 0.1/6.5 MB 532.5 kB/s eta 0:00:12\n",
      "    --------------------------------------- 0.2/6.5 MB 508.4 kB/s eta 0:00:13\n",
      "   - -------------------------------------- 0.2/6.5 MB 562.0 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.2/6.5 MB 550.0 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.3/6.5 MB 561.1 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.3/6.5 MB 587.7 kB/s eta 0:00:11\n",
      "   - -------------------------------------- 0.3/6.5 MB 575.5 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.3/6.5 MB 582.0 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.4/6.5 MB 587.5 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.4/6.5 MB 592.3 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.4/6.5 MB 592.3 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.4/6.5 MB 592.3 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.5/6.5 MB 589.3 kB/s eta 0:00:11\n",
      "   -- ------------------------------------- 0.5/6.5 MB 579.4 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.5/6.5 MB 574.6 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.5/6.5 MB 566.4 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.6/6.5 MB 569.5 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.6/6.5 MB 555.7 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.6/6.5 MB 567.3 kB/s eta 0:00:11\n",
      "   --- ------------------------------------ 0.6/6.5 MB 562.7 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.7/6.5 MB 559.2 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.7/6.5 MB 561.8 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.7/6.5 MB 565.2 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.7/6.5 MB 561.5 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.8/6.5 MB 570.6 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.8/6.5 MB 566.8 kB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 0.8/6.5 MB 561.7 kB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 0.8/6.5 MB 571.6 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 0.9/6.5 MB 568.1 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 0.9/6.5 MB 569.3 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 0.9/6.5 MB 569.3 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 0.9/6.5 MB 567.8 kB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 1.0/6.5 MB 569.6 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.0/6.5 MB 561.7 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.0/6.5 MB 563.1 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.0/6.5 MB 559.2 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.0/6.5 MB 556.0 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.1/6.5 MB 554.1 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.1/6.5 MB 555.8 kB/s eta 0:00:10\n",
      "   ------ --------------------------------- 1.1/6.5 MB 552.0 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.1/6.5 MB 555.3 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.2/6.5 MB 553.3 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.2/6.5 MB 550.0 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.2/6.5 MB 553.1 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.2/6.5 MB 549.8 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.3/6.5 MB 548.3 kB/s eta 0:00:10\n",
      "   ------- -------------------------------- 1.3/6.5 MB 549.8 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.3/6.5 MB 551.0 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.3/6.5 MB 553.1 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.4/6.5 MB 555.2 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.4/6.5 MB 553.5 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.4/6.5 MB 555.3 kB/s eta 0:00:10\n",
      "   -------- ------------------------------- 1.5/6.5 MB 556.6 kB/s eta 0:00:10\n",
      "   --------- ------------------------------ 1.5/6.5 MB 561.0 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.5/6.5 MB 559.5 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.5/6.5 MB 561.1 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.6/6.5 MB 562.7 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.6/6.5 MB 566.8 kB/s eta 0:00:09\n",
      "   --------- ------------------------------ 1.6/6.5 MB 559.2 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.6/6.5 MB 566.3 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.7/6.5 MB 561.8 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.7/6.5 MB 556.4 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.7/6.5 MB 556.4 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.7/6.5 MB 553.2 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.7/6.5 MB 553.2 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.8/6.5 MB 551.4 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.8/6.5 MB 546.7 kB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 1.8/6.5 MB 545.1 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.8/6.5 MB 543.5 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.8/6.5 MB 543.5 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.8/6.5 MB 535.0 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.8/6.5 MB 530.8 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 529.6 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 529.6 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 525.9 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 519.8 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 516.4 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 516.4 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 510.6 kB/s eta 0:00:09\n",
      "   ----------- ---------------------------- 1.9/6.5 MB 509.7 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.0/6.5 MB 508.8 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.0/6.5 MB 505.3 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.0/6.5 MB 506.5 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.0/6.5 MB 501.1 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.0/6.5 MB 502.3 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.0/6.5 MB 501.5 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.1/6.5 MB 497.6 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.1/6.5 MB 497.6 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.1/6.5 MB 492.7 kB/s eta 0:00:09\n",
      "   ------------ --------------------------- 2.1/6.5 MB 490.2 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.1/6.5 MB 489.8 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.1/6.5 MB 486.8 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 486.3 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 483.5 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 483.5 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 481.3 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 480.9 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 478.2 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 477.8 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.2/6.5 MB 477.8 kB/s eta 0:00:09\n",
      "   ------------- -------------------------- 2.3/6.5 MB 470.5 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 2.3/6.5 MB 470.2 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.3/6.5 MB 466.9 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.3/6.5 MB 466.9 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.3/6.5 MB 463.1 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.3/6.5 MB 462.8 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.3/6.5 MB 462.8 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.3/6.5 MB 462.8 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 456.1 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 456.1 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 451.9 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 448.5 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 448.5 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 447.0 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 443.8 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 443.8 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 2.4/6.5 MB 442.5 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 442.4 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 438.1 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 438.1 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 436.9 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 433.9 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 433.9 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 432.8 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.5/6.5 MB 431.1 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.6/6.5 MB 431.1 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.6/6.5 MB 431.1 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.6/6.5 MB 429.4 kB/s eta 0:00:10\n",
      "   --------------- ------------------------ 2.6/6.5 MB 429.5 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 2.6/6.5 MB 429.6 kB/s eta 0:00:10\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 429.1 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 428.6 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 428.7 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 429.8 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 429.8 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 428.3 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 426.7 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.7/6.5 MB 426.7 kB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 2.8/6.5 MB 423.8 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 423.9 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 420.4 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 420.4 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 418.6 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 418.6 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 415.2 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.8/6.5 MB 414.4 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 414.6 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 414.6 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 411.4 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 411.6 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 410.3 kB/s eta 0:00:09\n",
      "   ----------------- ---------------------- 2.9/6.5 MB 409.6 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 2.9/6.5 MB 409.8 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.0/6.5 MB 409.4 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.0/6.5 MB 409.6 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.0/6.5 MB 408.4 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.0/6.5 MB 408.5 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.0/6.5 MB 409.6 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.0/6.5 MB 408.4 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.1/6.5 MB 408.6 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.1/6.5 MB 408.2 kB/s eta 0:00:09\n",
      "   ------------------ --------------------- 3.1/6.5 MB 409.2 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 3.1/6.5 MB 409.1 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 3.1/6.5 MB 410.1 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 3.2/6.5 MB 408.9 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 3.2/6.5 MB 410.9 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 3.2/6.5 MB 410.5 kB/s eta 0:00:09\n",
      "   ------------------- -------------------- 3.2/6.5 MB 411.2 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 3.3/6.5 MB 411.4 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 3.3/6.5 MB 412.8 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 3.3/6.5 MB 412.5 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 3.3/6.5 MB 414.3 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 3.3/6.5 MB 414.0 kB/s eta 0:00:08\n",
      "   -------------------- ------------------- 3.4/6.5 MB 415.4 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.4/6.5 MB 417.3 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.4/6.5 MB 416.9 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.5/6.5 MB 418.6 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.5/6.5 MB 419.1 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.5/6.5 MB 420.0 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.5/6.5 MB 421.4 kB/s eta 0:00:08\n",
      "   --------------------- ------------------ 3.6/6.5 MB 422.7 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 3.6/6.5 MB 424.0 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 3.6/6.5 MB 424.8 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 3.6/6.5 MB 426.1 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 3.7/6.5 MB 428.9 kB/s eta 0:00:07\n",
      "   ---------------------- ----------------- 3.7/6.5 MB 430.2 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 3.8/6.5 MB 431.4 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 3.8/6.5 MB 432.6 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 3.8/6.5 MB 434.9 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 3.9/6.5 MB 436.1 kB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 3.9/6.5 MB 436.5 kB/s eta 0:00:07\n",
      "   ------------------------ --------------- 3.9/6.5 MB 439.2 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 4.0/6.5 MB 440.3 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 4.0/6.5 MB 441.1 kB/s eta 0:00:06\n",
      "   ------------------------ --------------- 4.0/6.5 MB 443.7 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 4.1/6.5 MB 447.0 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 4.1/6.5 MB 448.1 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 4.1/6.5 MB 448.4 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 4.1/6.5 MB 447.6 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 4.2/6.5 MB 449.5 kB/s eta 0:00:06\n",
      "   ------------------------- -------------- 4.2/6.5 MB 452.7 kB/s eta 0:00:06\n",
      "   -------------------------- ------------- 4.2/6.5 MB 453.7 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 4.3/6.5 MB 456.9 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 4.3/6.5 MB 458.2 kB/s eta 0:00:05\n",
      "   -------------------------- ------------- 4.4/6.5 MB 461.0 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 4.4/6.5 MB 463.4 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 4.4/6.5 MB 463.7 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 4.5/6.5 MB 465.1 kB/s eta 0:00:05\n",
      "   --------------------------- ------------ 4.5/6.5 MB 467.6 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 4.6/6.5 MB 468.9 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 4.6/6.5 MB 470.5 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 4.6/6.5 MB 469.3 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 4.6/6.5 MB 469.3 kB/s eta 0:00:05\n",
      "   ---------------------------- ----------- 4.7/6.5 MB 470.0 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 4.7/6.5 MB 469.9 kB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 4.7/6.5 MB 470.0 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.7/6.5 MB 470.6 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.7/6.5 MB 470.1 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.8/6.5 MB 470.0 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.8/6.5 MB 470.1 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.8/6.5 MB 470.7 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.8/6.5 MB 470.8 kB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 4.9/6.5 MB 470.4 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 4.9/6.5 MB 472.2 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 4.9/6.5 MB 472.3 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 4.9/6.5 MB 471.2 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 5.0/6.5 MB 472.4 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 5.0/6.5 MB 472.5 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 5.0/6.5 MB 472.7 kB/s eta 0:00:04\n",
      "   ------------------------------ --------- 5.0/6.5 MB 473.2 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 5.1/6.5 MB 474.0 kB/s eta 0:00:04\n",
      "   ------------------------------- -------- 5.1/6.5 MB 474.8 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 5.1/6.5 MB 476.5 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 5.2/6.5 MB 477.3 kB/s eta 0:00:03\n",
      "   ------------------------------- -------- 5.2/6.5 MB 477.4 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 5.2/6.5 MB 478.8 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 5.3/6.5 MB 479.6 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 5.3/6.5 MB 481.3 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 5.3/6.5 MB 482.0 kB/s eta 0:00:03\n",
      "   -------------------------------- ------- 5.4/6.5 MB 482.7 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 5.4/6.5 MB 483.5 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 5.4/6.5 MB 484.9 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 5.5/6.5 MB 486.5 kB/s eta 0:00:03\n",
      "   --------------------------------- ------ 5.5/6.5 MB 487.4 kB/s eta 0:00:03\n",
      "   ---------------------------------- ----- 5.6/6.5 MB 489.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.6/6.5 MB 489.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.6/6.5 MB 485.9 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.6/6.5 MB 490.2 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.6/6.5 MB 489.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.7/6.5 MB 489.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 5.7/6.5 MB 490.2 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 5.7/6.5 MB 490.8 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 5.7/6.5 MB 491.3 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 5.8/6.5 MB 491.9 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 5.8/6.5 MB 491.9 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 5.8/6.5 MB 492.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 5.9/6.5 MB 494.1 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 5.9/6.5 MB 493.6 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 5.9/6.5 MB 494.3 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 6.0/6.5 MB 495.8 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 6.0/6.5 MB 496.4 kB/s eta 0:00:02\n",
      "   ------------------------------------ --- 6.0/6.5 MB 497.0 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.1/6.5 MB 498.3 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.1/6.5 MB 498.9 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.1/6.5 MB 499.7 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.5 MB 500.2 kB/s eta 0:00:01\n",
      "   ------------------------------------- -- 6.2/6.5 MB 500.9 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.2/6.5 MB 501.4 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.2/6.5 MB 502.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.5 MB 504.1 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 6.3/6.5 MB 504.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------  6.3/6.5 MB 505.8 kB/s eta 0:00:01\n",
      "   ---------------------------------------  6.4/6.5 MB 506.4 kB/s eta 0:00:01\n",
      "   ---------------------------------------  6.4/6.5 MB 507.9 kB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.5 MB 509.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------  6.5/6.5 MB 509.6 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 6.5/6.5 MB 509.9 kB/s eta 0:00:00\n",
      "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
      "   ---------------------------------------- 0.0/527.3 kB ? eta -:--:--\n",
      "   -- ------------------------------------- 30.7/527.3 kB 1.3 MB/s eta 0:00:01\n",
      "   ----- --------------------------------- 71.7/527.3 kB 975.2 kB/s eta 0:00:01\n",
      "   ------- ------------------------------ 102.4/527.3 kB 837.8 kB/s eta 0:00:01\n",
      "   ----------- -------------------------- 153.6/527.3 kB 913.1 kB/s eta 0:00:01\n",
      "   ------------- ------------------------ 184.3/527.3 kB 853.3 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 235.5/527.3 kB 901.1 kB/s eta 0:00:01\n",
      "   ------------------- ------------------ 266.2/527.3 kB 907.8 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 317.4/527.3 kB 893.0 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 368.6/527.3 kB 916.6 kB/s eta 0:00:01\n",
      "   ---------------------------- --------- 399.4/527.3 kB 922.1 kB/s eta 0:00:01\n",
      "   ------------------------------ ------- 430.1/527.3 kB 924.8 kB/s eta 0:00:01\n",
      "   ---------------------------------- --- 481.3/527.3 kB 942.1 kB/s eta 0:00:01\n",
      "   -------------------------------------  522.2/527.3 kB 936.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 527.3/527.3 kB 945.2 kB/s eta 0:00:00\n",
      "Downloading sentencepiece-0.2.0-cp39-cp39-win_amd64.whl (991 kB)\n",
      "   ---------------------------------------- 0.0/991.5 kB ? eta -:--:--\n",
      "   - ------------------------------------- 41.0/991.5 kB 960.0 kB/s eta 0:00:01\n",
      "   -- ------------------------------------ 71.7/991.5 kB 975.2 kB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 122.9/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ----- -------------------------------- 153.6/991.5 kB 913.1 kB/s eta 0:00:01\n",
      "   -------- ------------------------------- 204.8/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 256.0/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 317.4/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 368.6/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 419.8/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 471.0/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 522.2/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 563.2/991.5 kB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 634.9/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 686.1/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 747.5/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 798.7/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 849.9/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 890.9/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 962.6/991.5 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 991.5/991.5 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "   ---------------------------------------- 0.0/101.7 kB ? eta -:--:--\n",
      "   ------------------------ --------------- 61.4/101.7 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 101.7/101.7 kB 1.2 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading aiohttp-3.10.5-cp39-cp39-win_amd64.whl (379 kB)\n",
      "   ---------------------------------------- 0.0/379.8 kB ? eta -:--:--\n",
      "   ------ --------------------------------- 61.4/379.8 kB 1.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/379.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 163.8/379.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 235.5/379.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 286.7/379.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 286.7/379.8 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  378.9/379.8 kB 1.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 379.8/379.8 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading sentry_sdk-2.13.0-py2.py3-none-any.whl (309 kB)\n",
      "   ---------------------------------------- 0.0/309.1 kB ? eta -:--:--\n",
      "   ----- --------------------------------- 41.0/309.1 kB 653.6 kB/s eta 0:00:01\n",
      "   ----------- --------------------------- 92.2/309.1 kB 880.9 kB/s eta 0:00:01\n",
      "   ---------------- --------------------- 133.1/309.1 kB 983.0 kB/s eta 0:00:01\n",
      "   ---------------------- --------------- 184.3/309.1 kB 930.9 kB/s eta 0:00:01\n",
      "   -------------------------- ----------- 215.0/309.1 kB 939.4 kB/s eta 0:00:01\n",
      "   -------------------------------- ----- 266.2/309.1 kB 966.0 kB/s eta 0:00:01\n",
      "   -------------------------------------- 309.1/309.1 kB 957.8 kB/s eta 0:00:00\n",
      "Downloading multiprocess-0.70.16-py39-none-any.whl (133 kB)\n",
      "   ---------------------------------------- 0.0/133.4 kB ? eta -:--:--\n",
      "   ------------ --------------------------- 41.0/133.4 kB 1.9 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 92.2/133.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  133.1/133.4 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 133.4/133.4 kB 1.1 MB/s eta 0:00:00\n",
      "Downloading setproctitle-1.3.3-cp39-cp39-win_amd64.whl (11 kB)\n",
      "Downloading xxhash-3.5.0-cp39-cp39-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.4.0-py3-none-any.whl (12 kB)\n",
      "Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-win_amd64.whl (50 kB)\n",
      "   ---------------------------------------- 0.0/50.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 50.7/50.7 kB 1.3 MB/s eta 0:00:00\n",
      "Downloading multidict-6.0.5-cp39-cp39-win_amd64.whl (28 kB)\n",
      "Downloading yarl-1.9.4-cp39-cp39-win_amd64.whl (76 kB)\n",
      "   ---------------------------------------- 0.0/76.9 kB ? eta -:--:--\n",
      "   --------------- ------------------------ 30.7/76.9 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 76.9/76.9 kB 1.1 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py): started\n",
      "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16186 sha256=6c141684affc6aec56093d43a8fbafe8282faa53bb1ef61f0266ed9b55c7cd6d\n",
      "  Stored in directory: c:\\users\\dell\\appdata\\local\\pip\\cache\\wheels\\e2\\a5\\92\\2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
      "Successfully built seqeval\n",
      "Installing collected packages: sentencepiece, xxhash, tensorboardx, setproctitle, sentry-sdk, multidict, frozenlist, docker-pycreds, dill, async-timeout, aiohappyeyeballs, yarl, multiprocess, aiosignal, wandb, seqeval, aiohttp, datasets, simpletransformers\n",
      "Successfully installed aiohappyeyeballs-2.4.0 aiohttp-3.10.5 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.21.0 dill-0.3.8 docker-pycreds-0.4.0 frozenlist-1.4.1 multidict-6.0.5 multiprocess-0.70.16 sentencepiece-0.2.0 sentry-sdk-2.13.0 seqeval-1.2.2 setproctitle-1.3.3 simpletransformers-0.70.1 tensorboardx-2.6.2.2 wandb-0.17.7 xxhash-3.5.0 yarl-1.9.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install simpletransformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--bert-base-uncased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "1it [00:12, 12.04s/it]\n",
      "Epoch 1 of 3:   0%|          | 0/3 [00:00<?, ?it/s]c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "Epochs 1/3. Running Loss:    0.7023: 100%|██████████| 1/1 [00:29<00:00, 29.46s/it]\n",
      "Epochs 2/3. Running Loss:    0.7143: 100%|██████████| 1/1 [00:00<00:00,  3.25it/s]\n",
      "Epochs 3/3. Running Loss:    0.6930: 100%|██████████| 1/1 [00:00<00:00,  3.07it/s]\n",
      "Epoch 3 of 3: 100%|██████████| 3/3 [00:38<00:00, 12.89s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "# Prepare the training data\n",
    "train_data = [\n",
    "    [\"The movie was amazing\", 1],\n",
    "    [\"It was a boring movie\", 0],\n",
    "    [\"I had a great experience\", 1],\n",
    "    [\"I was bored during the movie\", 0],\n",
    "    [\"The movie was great\", 1],\n",
    "    [\"The movie was bad\", 0],\n",
    "    [\"The movie was good\", 1]\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "train_df = pd.DataFrame(train_data, columns=[\"text\", \"labels\"])\n",
    "\n",
    "# Define model arguments\n",
    "model_args = ClassificationArgs()\n",
    "model_args.num_train_epochs = 3\n",
    "model_args.learning_rate = 4e-5\n",
    "model_args.per_device_train_batch_size = 8\n",
    "model_args.per_device_eval_batch_size = 8\n",
    "\n",
    "# Initialize the model\n",
    "model = ClassificationModel(\n",
    "    \"bert\", \"bert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    args=model_args\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.train_model(train_df)\n",
    "\n",
    "# Optional: Save the model\n",
    "model.save_model(\"text_classifier_model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:40, 40.53s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Example test data\n",
    "test_data = [\n",
    "    [\"The movie was fantastic\", 1],\n",
    "    [\"I did not like the movie\", 0],\n",
    "    [\"It was a thrilling experience\", 1],\n",
    "    [\"The movie was a letdown\", 0]\n",
    "]\n",
    "\n",
    "# Convert to DataFrame\n",
    "test_df = pd.DataFrame(test_data, columns=[\"text\", \"labels\"])\n",
    "\n",
    "# Make predictions\n",
    "predictions, raw_outputs = model.predict(test_df[\"text\"].tolist())\n",
    "\n",
    "# Evaluate accuracy\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "true_labels = test_df[\"labels\"].tolist()\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(f'Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "55. How to perform text classification using spaCy ?\n",
    "Difficulty Level : L4\n",
    "\n",
    "Q. Build a text classifier using spacy that can classify IMDB reviews as positive or negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 320.0 kB/s eta 0:00:40\n",
      "     --------------------------------------- 0.0/12.8 MB 388.9 kB/s eta 0:00:33\n",
      "     --------------------------------------- 0.1/12.8 MB 737.3 kB/s eta 0:00:18\n",
      "      --------------------------------------- 0.2/12.8 MB 1.3 MB/s eta 0:00:10\n",
      "     - -------------------------------------- 0.5/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.0/12.8 MB 3.7 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.0/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.0/12.8 MB 6.3 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.2/12.8 MB 5.8 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.2/12.8 MB 5.0 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.6/12.8 MB 5.5 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 5.6 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 2.9/12.8 MB 4.9 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.1/12.8 MB 4.8 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 3.9/12.8 MB 5.1 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.1/12.8 MB 5.2 MB/s eta 0:00:02\n",
      "     ------------ --------------------------- 4.2/12.8 MB 5.0 MB/s eta 0:00:02\n",
      "     ------------- -------------------------- 4.4/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.5/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 4.7/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 4.8/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 5.1/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.6/12.8 MB 4.9 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ----------------- ---------------------- 5.7/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------------ --------------------- 6.0/12.8 MB 4.8 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.1/12.8 MB 4.7 MB/s eta 0:00:02\n",
      "     ------------------- -------------------- 6.2/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.5/12.8 MB 4.6 MB/s eta 0:00:02\n",
      "     -------------------- ------------------- 6.7/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 6.8/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     --------------------- ------------------ 7.0/12.8 MB 4.5 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.6/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.7/12.8 MB 4.4 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 4.3 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.0/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.1/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.3/12.8 MB 4.2 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.5/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.6/12.8 MB 4.1 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.8/12.8 MB 4.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     --------------------------- ------------ 9.0/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 3.9 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 9.2/12.8 MB 3.8 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 3.7 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.4/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 3.6 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ----------------------------- ---------- 9.6/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.7/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.8/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.8/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 9.9/12.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 9.9/12.8 MB 3.3 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.0/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.2/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 3.0 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.4/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.9 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.5/12.8 MB 2.8 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 2.7 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.6 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.7/12.8 MB 2.5 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 2.3 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.9/12.8 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.3 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 10.9/12.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 2.1 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 2.0 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.1/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.2/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.2/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.4/12.8 MB 1.8 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 1.7 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.7/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.8/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.9/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.6 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.0/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.2/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.2/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.5 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.4/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.5/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.5/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 1.3 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 1.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dell\\miniconda3\\envs\\vio\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.training import Example\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "# Load the spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create and add the TextCategorizer to the pipeline\n",
    "textcat = nlp.add_pipe(\"textcat\", last=True)\n",
    "\n",
    "# Add labels to the TextCategorizer\n",
    "textcat.add_label(\"POSITIVE\")\n",
    "textcat.add_label(\"NEGATIVE\")\n",
    "\n",
    "def load_data(limit=0, split=0.8):\n",
    "    \"\"\"Load data from the IMDB dataset.\"\"\"\n",
    "    import thinc\n",
    "    # Partition off part of the train data for evaluation\n",
    "    train_data, _ = thinc.extra.datasets.imdb()\n",
    "    random.shuffle(train_data)\n",
    "    train_data = train_data[:limit] if limit > 0 else train_data\n",
    "    texts, labels = zip(*train_data)\n",
    "    cats = [{\"POSITIVE\": bool(y), \"NEGATIVE\": not bool(y)} for y in labels]\n",
    "    split_idx = int(len(train_data) * split)\n",
    "    return (texts[:split_idx], cats[:split_idx]), (texts[split_idx:], cats[split_idx:])\n",
    "\n",
    "# Load the IMDB dataset\n",
    "print(\"Loading IMDB data...\")\n",
    "(train_texts, train_cats), (dev_texts, dev_cats) = load_data(limit=1000)  # Adjust limit as needed\n",
    "\n",
    "# Prepare the training data\n",
    "train_data = list(zip(train_texts, [{\"cats\": cats} for cats in train_cats]))\n",
    "\n",
    "# Get names of other pipes to disable them during training\n",
    "pipe_exceptions = [\"textcat\"]\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "\n",
    "# Training the text classifier\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    print(\"{:^5}\\t{:^5}\\t{:^5}\\t{:^5}\".format(\"LOSS\", \"P\", \"R\", \"F\"))\n",
    "    batch_sizes = compounding(4.0, 32.0, 1.001)\n",
    "    for epoch in range(10):  # Adjust number of epochs as needed\n",
    "        losses = {}\n",
    "        # Batch up the examples using spaCy's minibatch\n",
    "        random.shuffle(train_data)\n",
    "        batches = minibatch(train_data, size=batch_sizes)\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            examples = [Example.from_dict(nlp.make_doc(text), annotation) for text, annotation in zip(texts, annotations)]\n",
    "            nlp.update(examples, drop=0.5, losses=losses)\n",
    "        print(f\"Epoch {epoch + 1}: Losses {losses}\")\n",
    "\n",
    "# Save the model\n",
    "nlp.to_disk(\"text_classifier_model\")\n",
    "print(\"Model saved to 'text_classifier_model'\")\n",
    "\n",
    "# Test the model\n",
    "test_texts = [\n",
    "    \"I really enjoyed the movie.\",\n",
    "    \"It was a terrible experience.\",\n",
    "    \"The film was quite good.\",\n",
    "    \"I did not like it at all.\"\n",
    "]\n",
    "\n",
    "# Load the trained model\n",
    "nlp = spacy.load(\"text_classifier_model\")\n",
    "\n",
    "# Make predictions\n",
    "for text in test_texts:\n",
    "    doc = nlp(text)\n",
    "    print(f\"Text: {text}\\nPrediction: {doc.cats}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "56. How to translate the text (using simpletransformers) ?\n",
    "Difficulty Level : L3\n",
    "\n",
    "Q. Translate the given list of texts from English to Dutch using simpletransformers package\n",
    "\n",
    "Input :\n",
    "\n",
    "['Our experienced writers travel the world to bring you informative and inspirational features, destination roundups, travel ideas, tips and beautiful photos in order to help you plan your next holiday',\n",
    "                  'Each part of Germany is different, and there are thousands of memorable places to visit.',\n",
    "                  \"Christmas Markets originated in Germany, and the tradition dates to the Late Middle Ages.\",\n",
    "                  \"Garmisch-Partenkirchen is a small town in Bavaria, near Germany’s highest mountain Zugspitze, which rises to 9,718 feet (2,962 meters)\",\n",
    "                  \"It’s one of the country’s top alpine destinations, extremely popular during the winter\",\n",
    "                  \"In spring, take a road trip through Bavaria and enjoy the view of the dark green Alps and the first alpine wildflowers. \"]\n",
    "Desired Output :\n",
    "\n",
    "['Unsere erfahrenen Autoren reisen die Welt, um Ihnen informative und inspirierende Funktionen, Destination Rund',\n",
    "'Jeder Teil Deutschlands ist anders, und es gibt Tausende von denkwürdigen Orten zu besuchen.',\n",
    "'Weihnachtsmärkte entstanden in Deutschland, und die Tradition stammt aus dem späten Mittelalter.',\n",
    "'Garmisch-Partenkirchen ist eine kleine Stadt in Bayern, nahe Deutschland.Die Zug',\n",
    "'Es ist eines der Top-Alpenziele des Landes, sehr beliebt im Winter',\n",
    "'Im Frühjahr machen Sie eine Roadtrip durch Bayern und genießen den Blick auf die dunkelgrünen Alpen']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--Helsinki-NLP--opus-mt-en-nl. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Our experienced writers travel the world to bring you informative and inspirational features, destination roundups, travel ideas, tips and beautiful photos in order to help you plan your next holiday\n",
      "Translated: Onze ervaren schrijvers reizen de wereld rond om u informatieve en inspirerende functies, bestemmingsrondleidingen, reistips, tips en mooie foto's te brengen om u te helpen uw volgende vakantie te plannen\n",
      "\n",
      "Original: Each part of Germany is different, and there are thousands of memorable places to visit.\n",
      "Translated: Elk deel van Duitsland is anders, en er zijn duizenden memorabele plaatsen om te bezoeken.\n",
      "\n",
      "Original: Christmas Markets originated in Germany, and the tradition dates to the Late Middle Ages.\n",
      "Translated: Kerstmarkten ontstaan in Duitsland, en de traditie dateert uit de late middeleeuwen.\n",
      "\n",
      "Original: Garmisch-Partenkirchen is a small town in Bavaria, near Germany’s highest mountain Zugspitze, which rises to 9,718 feet (2,962 meters)\n",
      "Translated: Garmisch-Partenkirchen is een klein stadje in Beieren, in de buurt van de hoogste berg Zugspitze, die stijgt tot 9,718 voet (2.962 meter)\n",
      "\n",
      "Original: It’s one of the country’s top alpine destinations, extremely popular during the winter\n",
      "Translated: Het is een van de hoogste alpine bestemmingen van het land, zeer populair tijdens de winter\n",
      "\n",
      "Original: In spring, take a road trip through Bavaria and enjoy the view of the dark green Alps and the first alpine wildflowers.\n",
      "Translated: Neem in het voorjaar een roadtrip door Beieren en geniet van het uitzicht op de donkergroene Alpen en de eerste wilde alpenbloemen.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "# Load the translation model and tokenizer\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-nl'\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Define the texts to translate\n",
    "texts = [\n",
    "    'Our experienced writers travel the world to bring you informative and inspirational features, destination roundups, travel ideas, tips and beautiful photos in order to help you plan your next holiday',\n",
    "    'Each part of Germany is different, and there are thousands of memorable places to visit.',\n",
    "    \"Christmas Markets originated in Germany, and the tradition dates to the Late Middle Ages.\",\n",
    "    \"Garmisch-Partenkirchen is a small town in Bavaria, near Germany’s highest mountain Zugspitze, which rises to 9,718 feet (2,962 meters)\",\n",
    "    \"It’s one of the country’s top alpine destinations, extremely popular during the winter\",\n",
    "    \"In spring, take a road trip through Bavaria and enjoy the view of the dark green Alps and the first alpine wildflowers.\"\n",
    "]\n",
    "\n",
    "# Function to translate text\n",
    "def translate_text(texts):\n",
    "    translated_texts = []\n",
    "    for text in texts:\n",
    "        # Tokenize the input text\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "        # Perform translation\n",
    "        translated = model.generate(**inputs)\n",
    "        # Decode the output\n",
    "        translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "        translated_texts.append(translated_text)\n",
    "    return translated_texts\n",
    "\n",
    "# Translate the texts\n",
    "translations = translate_text(texts)\n",
    "\n",
    "# Print the translations\n",
    "for original, translated in zip(texts, translations):\n",
    "    print(f\"Original: {original}\")\n",
    "    print(f\"Translated: {translated}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "57. How to create a Question-Answering system from given context\n",
    "Difficulty Level : L4\n",
    "\n",
    "Q. Build a Question Answering model that answers questions from the given context using transformers package\n",
    "\n",
    "Input :\n",
    "\n",
    "context=\"\"\" Harry Potter is the best book series according to many people. Harry Potter was written by JK.Rowling .\n",
    "It is afantasy based novel that provides a thrilling experience to readers.\"\"\"\n",
    "\n",
    "question=\"What is Harry Potter ?\"\n",
    "Desired Output :\n",
    "\n",
    "{'score': 0.2375375191101107, 'start': 17, 'end': 37, 'answer': 'the best book series'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert/distilbert-base-cased-distilled-squad).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-cased-distilled-squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 0.10919643938541412, 'start': 16, 'end': 36, 'answer': 'the best book series'}\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the pre-trained model and tokenizer\n",
    "qa_pipeline = pipeline(\"question-answering\")\n",
    "\n",
    "# Define the context and question\n",
    "context = \"\"\"Harry Potter is the best book series according to many people. Harry Potter was written by JK.Rowling.\n",
    "It is a fantasy based novel that provides a thrilling experience to readers.\"\"\"\n",
    "question = \"What is Harry Potter?\"\n",
    "\n",
    "# Get the answer\n",
    "result = qa_pipeline(question=question, context=context)\n",
    "\n",
    "# Print the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "58. How to do text generation starting from a given piece of text?\n",
    "Difficulty Level : L4\n",
    "\n",
    "Q. Generate text based on the the starting provided.\n",
    "\n",
    "Input :\n",
    "\n",
    "starting=\"It was a bright\"\n",
    "Desired Output :\n",
    "\n",
    "'It was a bright day in New Jersey\\'s capitol,\" the senator told a reporter after the rally. \"It\\'s a sunny day in New Hampshire, there\\'s a great deal of sunshine.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It was a bright day for the city of Toronto.\n",
      "\n",
      "The city's new mayor, Rob Ford, has been in office for just over a year. He's been in office for just over a year.\n",
      "\n",
      "The city's new mayor\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "\n",
    "# Load pre-trained model and tokenizer\n",
    "model_name = 'gpt2'  # You can also use 'gpt2-medium', 'gpt2-large', or 'gpt2-xl' for more complex tasks\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(starting_text, max_length=50):\n",
    "    # Encode the starting text\n",
    "    input_ids = tokenizer.encode(starting_text, return_tensors='pt')\n",
    "    \n",
    "    # Generate text\n",
    "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1, \n",
    "                            pad_token_id=tokenizer.eos_token_id)\n",
    "    \n",
    "    # Decode and return the generated text\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text\n",
    "\n",
    "# Define the starting text\n",
    "starting_text = \"It was a bright\"\n",
    "\n",
    "# Generate and print the text\n",
    "generated_text = generate_text(starting_text)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "59. How to classify a text as positive or negative sentiment with transformers?\n",
    "Difficulty Level : L4\n",
    "\n",
    "Q. Find out whether a given text is postive or negative sentiment along with score for predictions\n",
    "\n",
    "Input text:\n",
    "\n",
    "text1=\"It is a pleasant day, I am going for a walk\"\n",
    "text2=\"I have a terrible headache\"\n",
    "\n",
    "\n",
    "Desired Output :\n",
    "\n",
    "[{'label': 'POSITIVE', 'score': 0.9998570084571838}]\n",
    "[{'label': 'NEGATIVE', 'score': 0.9994378089904785}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "c:\\Users\\DELL\\miniconda3\\envs\\vio\\lib\\site-packages\\huggingface_hub\\file_download.py:157: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\DELL\\.cache\\huggingface\\hub\\models--distilbert--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998569488525391}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.9994377493858337}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Initialize the sentiment-analysis pipeline\n",
    "sentiment_analyzer = pipeline(task=\"sentiment-analysis\")\n",
    "\n",
    "# Define the input texts\n",
    "texts = [\n",
    "    \"It is a pleasant day, I am going for a walk\",\n",
    "    \"I have a terrible headache\"\n",
    "]\n",
    "\n",
    "# Analyze the sentiment of each text\n",
    "results = [sentiment_analyzer(text) for text in texts]\n",
    "\n",
    "# Print the results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
